
<p align="center">
    <a> <img src="assets/LLM_logo.png" width="400"/></a>
<p>
<p align="center">
    <a href="http://deepke.zjukg.cn">
        <img alt="Documentation" src="https://img.shields.io/badge/demo-website-blue">
    </a>
    <a href="https://pypi.org/project/deepke/#files">
        <img alt="PyPI" src="https://img.shields.io/pypi/v/deepke">
    </a>
    <a href="https://github.com/zjunlp/DeepKE/blob/master/LICENSE">
        <img alt="GitHub" src="https://img.shields.io/github/license/zjunlp/deepke">
    </a>
    <a href="http://zjunlp.github.io/DeepKE">
        <img alt="Documentation" src="https://img.shields.io/badge/doc-website-red">
    </a>
    <a href="https://colab.research.google.com/drive/1vS8YJhJltzw3hpJczPt24O0Azcs3ZpRi?usp=sharing">
        <img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg">
    </a>
</p>



<p align="center">
    <b> ç®€ä½“ä¸­æ–‡ | <a href="https://github.com/zjunlp/DeepKE/blob/main/example/llm/README.md">English</a> </b>
</p>


<h1 align="center">
    <p>DeepKE-LLM: åŸºäºæ·±åº¦å­¦ä¹ çš„å¼€æºä¸­æ–‡çŸ¥è¯†å›¾è°±æŠ½å–æ¡†æ¶ ï¼ˆå¤§æ¨¡å‹ç‰ˆï¼‰</p>
</h1>



# ğŸ“Œ ä¸Šä¸‹æ–‡å­¦ä¹ 

## ğŸ“— å•æ¬¡æ¨ç†

è¿è¡Œå‘½ä»¤ï¼š

```bash
python run.py --mood icl
```

[é…ç½®ç¤ºä¾‹](./examples/incontext_learning/icl_qwen.yaml)ï¼š

```yaml
engine: "Qwen"
model_id: "your-model-path"
temperature: 0.3
top_p: 0.9
max_tokens: 512
task: "da"
language: "ch"
in_context:
text_input: "åˆ›ç«‹"
domain:
labels: "äººç‰©, å…¬å¸"
```

å‚æ•°è¯´æ˜ï¼š

| å‚æ•°åç§°    | ç±»å‹  | æ„ä¹‰                                                         | é™å®š                                                         |
| ----------- | ----- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| engine      | str   | è¡¨ç¤ºæ‰€ç”¨çš„å¤§æ¨¡å‹åç§°ã€‚                                       | **å¿…é¡»**è¦æœ‰ï¼Œä¸”**å¿…é¡»**ä¸º `MODEL_LIST `ä¹‹ä¸€ã€‚               |
| api_key     | str   | ç”¨æˆ·çš„APIå¯†é’¥ã€‚                                              | è‹¥æ¨¡å‹ä¸ºé—­æºï¼Œåˆ™**å¿…é¡»**æä¾›ã€‚                               |
| base_url    | str   | åŸºç¡€ URLï¼Œç”¨äºæŒ‡å®š API è¯·æ±‚çš„åŸºç¡€åœ°å€ã€‚                      |                                                              |
| temperature | float | ç”¨äºæ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ã€‚                                   |                                                              |
| top_p       | float | æ ¸é‡‡æ ·ï¼ˆTop-pï¼‰å‚æ•°ï¼Œç”¨äºæ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§ã€‚              |                                                              |
| max_tokens  | int   | æœ€å¤§ token æ•°ï¼Œç”¨äºé™åˆ¶ç”Ÿæˆæ–‡æœ¬çš„é•¿åº¦ã€‚                      |                                                              |
| stop        | str   | åœæ­¢è¯ï¼Œç”¨äºæŒ‡å®šç”Ÿæˆæ–‡æœ¬æ—¶çš„ç»ˆæ­¢æ¡ä»¶ã€‚                       |                                                              |
| task        | str   | å‚æ•°ç”¨äºæŒ‡å®šä»»åŠ¡ç±»å‹ï¼Œå…¶ä¸­`ner`è¡¨ç¤ºå‘½åå®ä½“è¯†åˆ«ä»»åŠ¡ï¼Œ`re`è¡¨ç¤ºå…³ç³»æŠ½å–ä»»åŠ¡`ee`è¡¨ç¤ºäº‹ä»¶æŠ½å–ä»»åŠ¡ï¼Œ`rte`è¡¨ç¤ºä¸‰å…ƒç»„æŠ½å–ä»»åŠ¡ã€‚ | **å¿…é¡»**è¦æœ‰ï¼Œä¸”**å¿…é¡»**ä¸º `TASK_LIST` ä¹‹ä¸€ã€‚                |
| language    | str   | è¡¨ç¤ºä»»åŠ¡çš„è¯­è¨€ã€‚                                             | **å¿…é¡»**è¦æœ‰ï¼Œä¸”**å¿…é¡»**ä¸º `LANGUAGE_LIST` ä¹‹ä¸€ã€‚            |
| in_context  | bool  | æ˜¯å¦ä¸ºé›¶æ ·æœ¬è®¾å®šï¼Œä¸º`False`æ—¶è¡¨ç¤ºåªä½¿ç”¨instructionæç¤ºæ¨¡å‹è¿›è¡Œä¿¡æ¯æŠ½å–ï¼Œä¸º`True`æ—¶è¡¨ç¤ºä½¿ç”¨in-contextçš„å½¢å¼è¿›è¡Œä¿¡æ¯æŠ½å–ã€‚ |                                                              |
| instruction | str   | è§„å®šç”¨æˆ·è‡ªå®šä¹‰çš„æç¤ºæŒ‡ä»¤ï¼Œå½“ä¸ºç©ºæ—¶é‡‡ç”¨é»˜è®¤çš„æŒ‡ä»¤ã€‚           | ï¼ˆä¸å»ºè®®ä½¿ç”¨ï¼‰                                               |
| data_path   | str   | è¡¨ç¤ºin-context examplesçš„å­˜å‚¨ç›®å½•ï¼Œé»˜è®¤ä¸º`data`æ–‡ä»¶å¤¹ã€‚      |                                                              |
| text_input  | str   | åœ¨å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡(`ner`)ä¸­ï¼Œ`text_input`å‚æ•°ä¸ºé¢„æµ‹æ–‡æœ¬ï¼›åœ¨å…³ç³»æŠ½å–ä»»åŠ¡(`re`)ä¸­ï¼Œ`text_input`å‚æ•°ä¸ºæ–‡æœ¬ï¼›åœ¨äº‹ä»¶æŠ½å–ä»»åŠ¡(`ee`)ä¸­ï¼Œ`text_input`å‚æ•°ä¸ºå¾…é¢„æµ‹æ–‡æœ¬ï¼›åœ¨ä¸‰å…ƒç»„æŠ½å–ä»»åŠ¡(`rte`)ä¸­ï¼Œ`text_input`å‚æ•°ä¸ºå¾…é¢„æµ‹æ–‡æœ¬ã€‚ | æ‰€æœ‰ä»»åŠ¡**å¿…é¡»**è¦æœ‰ã€‚                                       |
| domain      | str   | åœ¨å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡(`ner`)ä¸­ï¼Œ`domain`ä¸ºé¢„æµ‹æ–‡æœ¬æ‰€å±é¢†åŸŸï¼Œå¯ä¸ºç©ºï¼›åœ¨å…³ç³»æŠ½å–ä»»åŠ¡(`re`)ä¸­ï¼Œ`domain`ä¸ºæ–‡æœ¬æ‰€å±é¢†åŸŸï¼Œå¯ä¸ºç©ºï¼›åœ¨äº‹ä»¶æŠ½å–ä»»åŠ¡(`ee`)ä¸­ï¼Œ`domain`ä¸ºé¢„æµ‹æ–‡æœ¬æ‰€å±é¢†åŸŸï¼Œå¯ä¸ºç©ºï¼›åœ¨ä¸‰å…ƒç»„æŠ½å–ä»»åŠ¡(`rte`)ä¸­ï¼Œ`domain`ä¸ºé¢„æµ‹æ–‡æœ¬æ‰€å±é¢†åŸŸï¼Œå¯ä¸ºç©ºã€‚ | ä»»åŠ¡ä¸º nerã€reã€eeã€rte ä¹‹ä¸€æ—¶ï¼Œå»ºè®®è®¾ç½®ã€‚                   |
| labels      | str   | åœ¨å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡(`ner`)ä¸­ï¼Œ`labels`ä¸ºå®ä½“æ ‡ç­¾é›†ï¼Œå¦‚æ— è‡ªå®šä¹‰çš„æ ‡ç­¾é›†ï¼Œè¯¥å‚æ•°å¯ä¸ºç©ºï¼›åœ¨å…³ç³»æŠ½å–ä»»åŠ¡(`re`)ä¸­ï¼Œ`labels`ä¸ºå…³ç³»ç±»å‹æ ‡ç­¾é›†ï¼Œå¦‚æ— è‡ªå®šä¹‰çš„æ ‡ç­¾é›†ï¼Œè¯¥å‚æ•°å¯ä¸ºç©ºã€‚`da`ä¸­`lables`ä¸ºå¤´å°¾å®ä½“è¢«é¢„å…ˆåˆ†ç±»çš„ç±»å‹ã€‚ | ä»»åŠ¡ä¸º da æ—¶ï¼Œ**å¿…é¡»**è¦æœ‰ã€‚ä»»åŠ¡ä¸º nerã€re ä¹‹ä¸€æ—¶ï¼Œå»ºè®®è®¾ç½®ã€‚å¤šä¸ªæ ‡ç­¾æ—¶ï¼Œç”¨é€—å·åˆ†å‰²ã€‚ |
| head_entity | str   | å¾…é¢„æµ‹å…³ç³»çš„å¤´å®ä½“å’Œå°¾å®ä½“ã€‚                                 | ä»»åŠ¡ä¸º re æ—¶ï¼Œ**å¿…é¡»**è¦æœ‰ã€‚                                 |
| tail_entity | str   | å¾…é¢„æµ‹å…³ç³»çš„å¤´å®ä½“å’Œå°¾å®ä½“ã€‚                                 | ä»»åŠ¡ä¸º re æ—¶ï¼Œ**å¿…é¡»**è¦æœ‰ã€‚                                 |
| head_type   | str   | å¾…é¢„æµ‹å…³ç³»çš„å¤´å°¾å®ä½“ç±»å‹ã€‚                                   | ä»»åŠ¡ä¸º re æ—¶ï¼Œ**å¿…é¡»**è¦æœ‰ã€‚                                 |
| tail_type   | str   | å¾…é¢„æµ‹å…³ç³»çš„å¤´å°¾å®ä½“ç±»å‹ã€‚                                   | ä»»åŠ¡ä¸º re æ—¶ï¼Œ**å¿…é¡»**è¦æœ‰ã€‚                                 |

## ğŸ“š æ‰¹é‡æ¨ç†

æ•°æ®é›†æ”¯æŒï¼š

| åç§°       | ä¸‹è½½                                                         | æ•°é‡  | æè¿°                                                         |
| ---------- | ------------------------------------------------------------ | ----- | ------------------------------------------------------------ |
| InstructIE | [Google drive](https://drive.google.com/file/d/1raf0h98x3GgIhaDyNn1dLle9_HvwD6wT/view?usp=sharing) [Hugging Face](https://huggingface.co/datasets/zjunlp/InstructIE) [ModelScope](https://modelscope.cn/datasets/ZJUNLP/InstructIE) [WiseModel](https://wisemodel.cn/datasets/zjunlp/InstructIE) | 30w+  | **åŒè¯­**(ä¸­æ–‡å’Œè‹±æ–‡)åŸºäºä¸»é¢˜çš„ä¿¡æ¯æŠ½å–(IE)æŒ‡ä»¤æ•°æ®é›†         |
| IEPile     | [Google Drive](https://drive.google.com/file/d/1jPdvXOTTxlAmHkn5XkeaaCFXQkYJk5Ng/view?usp=sharing) [Hugging Face](https://huggingface.co/datasets/zjunlp/iepile) [WiseModel](https://wisemodel.cn/datasets/zjunlp/IEPile) [ModelScpoe](https://modelscope.cn/datasets/ZJUNLP/IEPile) | 200w+ | å¤§è§„æ¨¡(`0.32B` tokens)é«˜è´¨é‡**åŒè¯­**(ä¸­æ–‡å’Œè‹±æ–‡)ä¿¡æ¯æŠ½å–(IE)æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† |

æ•°æ®å‡†å¤‡åŒæ ·å‚è€ƒå¾®è°ƒéƒ¨åˆ†çš„æ•°æ®è½¬æ¢ã€‚

è¿è¡Œè„šæœ¬ï¼š

```bash
python run.py --mood icl_batch
```

[é…ç½®å‚è€ƒ](./examples/incontext_learning/icl_batch_chatgpt.yaml)ï¼š

```yaml
engine: "ChatGPT"
model_id: "gpt-3.5-turbo"
api_key: "your-api-key"
temperature: 0.3
top_p: 0.9
max_tokens: 512
stop: null
task: "re"
language: "ch"
in_context: false
instruction: ""
data_path: "data/ICL_Examples"
text_input: "../data/RE/try.json"
domain: ""
labels: [""]
head_entity: ""
head_type: ""
tail_entity: ""
tail_type: ""
```

å‚æ•°è¯´æ˜åŒå•æ¬¡æ¨ç†ã€‚

# ğŸ“Œ å¾®è°ƒ

## ğŸ› ï¸ ç¯å¢ƒ

è¯·é€šè¿‡ä»¥ä¸‹å‘½ä»¤ï¼Œåˆ›å»ºå¹¶é…ç½®å¥½ç¯å¢ƒï¼š

```bash
cd example/llm

mkdir -p models results lora

conda create -n deepke-llm python=3.9
conda activate deepke-llm

pip install -r requirements.txt
```


## ğŸ“Š æ•°æ®

ç°æœ‰æ•°æ®é›†ï¼š

| åç§°       | ä¸‹è½½                                                         | æ•°é‡  | æè¿°                                                         |
| ---------- | ------------------------------------------------------------ | ----- | ------------------------------------------------------------ |
| InstructIE | [1,Google drive](https://drive.google.com/file/d/1raf0h98x3GgIhaDyNn1dLle9_HvwD6wT/view?usp=sharing) <br/> [2,Hugging Face](https://huggingface.co/datasets/zjunlp/InstructIE) <br/> [3,ModelScope](https://modelscope.cn/datasets/ZJUNLP/InstructIE)<br/> [4,WiseModel](https://wisemodel.cn/datasets/zjunlp/InstructIE) | 30w+  | **åŒè¯­**(ä¸­æ–‡å’Œè‹±æ–‡)åŸºäºä¸»é¢˜çš„ä¿¡æ¯æŠ½å–(IE)æŒ‡ä»¤æ•°æ®é›†         |
| IEPile     | [1,Google Drive](https://drive.google.com/file/d/1jPdvXOTTxlAmHkn5XkeaaCFXQkYJk5Ng/view?usp=sharing) <br/> [2,Hugging Face](https://huggingface.co/datasets/zjunlp/iepile) <br/> [3,ModelScpoe](https://modelscope.cn/datasets/ZJUNLP/IEPile) <br/> [4,WiseModel](https://wisemodel.cn/datasets/zjunlp/IEPile) | 200w+ | å¤§è§„æ¨¡(`0.32B` tokens)é«˜è´¨é‡**åŒè¯­**(ä¸­æ–‡å’Œè‹±æ–‡)ä¿¡æ¯æŠ½å–(IE)æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† |


<details>
  <summary><b>InstructIEè¯¦ç»†ä¿¡æ¯</b></summary>
**ä¸€æ¡æ•°æ®çš„ç¤ºä¾‹**


```json
{
  "id": "bac7c32c47fddd20966e4ece5111690c9ce3f4f798c7c9dfff7721f67d0c54a5",
  "cate": "åœ°ç†åœ°åŒº",
  "text": "é˜¿å°”å¤«è¾¾å°”ï¼ˆæŒªå¨è¯­ï¼šAlvdalï¼‰æ˜¯æŒªå¨çš„ä¸€ä¸ªå¸‚é•‡ï¼Œä½äºå†…é™†éƒ¡ï¼Œè¡Œæ”¿ä¸­å¿ƒä¸ºé˜¿å°”å¤«è¾¾å°”æ‘ã€‚å¸‚é•‡é¢ç§¯ä¸º943å¹³æ–¹å…¬é‡Œï¼Œäººå£æ•°é‡ä¸º2,424äººï¼ˆ2018å¹´ï¼‰ï¼Œäººå£å¯†åº¦ä¸ºæ¯å¹³æ–¹å…¬é‡Œ2.6äººã€‚",
  "relation": [
    {"head": "é˜¿å°”å¤«è¾¾å°”", "head_type": "åœ°ç†åœ°åŒº", "relation": "é¢ç§¯", "tail": "943å¹³æ–¹å…¬é‡Œ", "tail_type": "åº¦é‡"},
    {"head": "é˜¿å°”å¤«è¾¾å°”", "head_type": "åœ°ç†åœ°åŒº", "relation": "åˆ«å", "tail": "Alvdal", "tail_type": "åœ°ç†åœ°åŒº"},
    {"head": "å†…é™†éƒ¡", "head_type": "åœ°ç†åœ°åŒº", "relation": "ä½äº", "tail": "æŒªå¨", "tail_type": "åœ°ç†åœ°åŒº"},
    {"head": "é˜¿å°”å¤«è¾¾å°”", "head_type": "åœ°ç†åœ°åŒº", "relation": "ä½äº", "tail": "å†…é™†éƒ¡", "tail_type": "åœ°ç†åœ°åŒº"},
    {"head": "é˜¿å°”å¤«è¾¾å°”", "head_type": "åœ°ç†åœ°åŒº", "relation": "äººå£", "tail": "2,424äºº", "tail_type": "åº¦é‡"}
  ]
}
```

å­—æ®µè¯´æ˜:

|   å­—æ®µ   |                             è¯´æ˜                             |
| :------: | :----------------------------------------------------------: |
|    id    |                   æ¯ä¸ªæ•°æ®ç‚¹çš„å”¯ä¸€æ ‡è¯†ç¬¦ã€‚                   |
|   cate   |           æ–‡æœ¬çš„ä¸»é¢˜ç±»åˆ«ï¼Œæ€»è®¡12ç§ä¸åŒçš„ä¸»é¢˜åˆ†ç±»ã€‚           |
|   text   |     æ¨¡å‹çš„è¾“å…¥æ–‡æœ¬ï¼Œç›®æ ‡æ˜¯ä»ä¸­æŠ½å–æ¶‰åŠçš„æ‰€æœ‰å…³ç³»ä¸‰å…ƒç»„ã€‚     |
| relation | æè¿°æ–‡æœ¬ä¸­åŒ…å«çš„å…³ç³»ä¸‰å…ƒç»„ï¼Œå³(head, head_type, relation, tail, tail_type)ã€‚ |

è½¬æ¢è¿‡ç¨‹è¯·å‚è€ƒæ•°æ®è½¬æ¢éƒ¨åˆ†ä»£ç ã€‚

</details>


<details>
  <summary><b>IEPileè¯¦ç»†ä¿¡æ¯</b></summary>
**ä¸€æ¡æ•°æ®çš„ç¤ºä¾‹**

```json
{
  "task": "NER",
  "source": "MSRA",
  "instruction": "{\"instruction\": \"ä½ æ˜¯ä¸“é—¨è¿›è¡Œå®ä½“æŠ½å–çš„ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„å®ä½“ï¼Œä¸å­˜åœ¨çš„å®ä½“ç±»å‹è¿”å›ç©ºåˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚\", \"schema\": [\"ç»„ç»‡æœºæ„\", \"åœ°ç†ä½ç½®\", \"äººç‰©\"], \"input\": \"å¯¹äºåº·æœ‰ä¸ºã€æ¢å¯è¶…ã€è°­å—£åŒã€ä¸¥å¤è¿™äº›ä»æ—§æ–‡åŒ–è¥å’ä¸­èµ°æ¥çš„å¹´è½»â€œå¸ƒè¡£â€ï¼Œä»–ä»¬èƒŒè´Ÿç€æ²‰é‡çš„å†å²åŒ…è¢±ï¼Œèƒ½å¤ŸæŒ£è„±æ—§ä¼ ç»Ÿçš„æŸç¼šï¼Œä¸ºæ‹¯æ•‘æ°‘æ—çš„å±äº¡è€ŒçŒ®èº«ï¼Œå®åœ¨æ˜¯ä¸­åæ°‘æ—çš„è„Šæ¢ã€‚\"}",
  "output": "{\"ç»„ç»‡æœºæ„\": [], \"åœ°ç†ä½ç½®\": [\"ä¸­å\"], \"äººç‰©\": [\"åº·æœ‰ä¸º\", \"æ¢å¯è¶…\", \"è°­å—£åŒ\", \"ä¸¥å¤\"]}"
}
```

å­—æ®µè¯´æ˜:

|    å­—æ®µ     |                             è¯´æ˜                             |
| :---------: | :----------------------------------------------------------: |
|    task     | è¯¥å®ä¾‹æ‰€å±çš„ä»»åŠ¡, (`NER`ã€`RE`ã€`EE`ã€`EET`ã€`EEA`) 5ç§ä»»åŠ¡ä¹‹ä¸€ã€‚ |
|   source    |                      è¯¥å®ä¾‹æ‰€å±çš„æ•°æ®é›†                      |
| instruction | è¾“å…¥æ¨¡å‹çš„æŒ‡ä»¤, ç»è¿‡json.dumpså¤„ç†æˆJSONå­—ç¬¦ä¸², åŒ…æ‹¬`"instruction"`, `"schema"`, `"input"`ä¸‰ä¸ªå­—æ®µ |
|   output    | è¾“å‡º, é‡‡ç”¨å­—å…¸çš„jsonå­—ç¬¦ä¸²çš„æ ¼å¼, keyæ˜¯schema, valueæ˜¯æŠ½å–å‡ºçš„å†…å®¹ |

åœ¨`IEPile`ä¸­, **`instruction`** çš„æ ¼å¼é‡‡çº³äº†ç±»JSONå­—ç¬¦ä¸²çš„ç»“æ„ï¼Œå®è´¨ä¸Šæ˜¯ä¸€ç§å­—å…¸å‹å­—ç¬¦ä¸²ï¼Œå®ƒç”±ä»¥ä¸‹ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†æ„æˆï¼š
(1) **`'instruction'`**: ä»»åŠ¡æè¿°, å®ƒæ¦‚è¿°äº†æŒ‡ä»¤çš„æ‰§è¡Œä»»åŠ¡(`NER`ã€`RE`ã€`EE`ã€`EET`ã€`EEA`ä¹‹ä¸€)ã€‚
(2) **`'schema'`**: å¾…æŠ½å–çš„schema(`å®ä½“ç±»å‹`, `å…³ç³»ç±»å‹`, `äº‹ä»¶ç±»å‹`)åˆ—è¡¨ã€‚
(3) **`'input'`**: å¾…æŠ½å–çš„æ–‡æœ¬ã€‚

</details>

ç¡®ä¿ç»“æ„å¦‚ä¸‹ï¼š

```
DeepKE/example/llm/data
â”œâ”€â”€ train.json    # è®­ç»ƒé›†
â””â”€â”€ dev.json      # éªŒè¯é›†
```

æ•°æ®è½¬æ¢ï¼š

è¿™é‡Œéœ€è¦å‡†å¤‡**è®­ç»ƒæ•°æ®é›†**å’Œ**æµ‹è¯•æ•°æ®é›†**ã€‚

> åœ¨ä½¿ç”¨ [convert_func.py](./instruction/convert_func.py) è„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿å‚è€ƒäº† [data](./data) ç›®å½•ã€‚è¯¥ç›®å½•è¯¦ç»†è¯´æ˜äº†æ¯ç§ä»»åŠ¡æ‰€éœ€çš„æ•°æ®æ ¼å¼è¦æ±‚ã€‚ `sample.json` æè¿°äº†è½¬æ¢å‰æ•°æ®çš„æ ¼å¼ï¼Œ`schema.json` å±•ç¤ºäº† schema çš„ç»„ç»‡ç»“æ„ï¼Œ `train.json` æè¿°äº†è½¬æ¢åçš„æ•°æ®æ ¼å¼ã€‚

> æ­¤å¤–ï¼Œå¯ç›´æ¥ä½¿ç”¨åŒ…å«12ä¸ªä¸»é¢˜ï¼ˆå¦‚äººç‰©ã€äº¤é€šå·¥å…·ã€è‰ºæœ¯ä½œå“ã€è‡ªç„¶ç§‘å­¦ã€äººé€ ç‰©å“ã€å¤©æ–‡å¯¹è±¡ç­‰ï¼‰çš„ä¸­è‹±åŒè¯­ä¿¡æ¯æŠ½å–æ•°æ®é›† [zjunlp/InstructIE](https://huggingface.co/datasets/zjunlp/InstructIE)ã€‚

1. é¦–å…ˆ, å‡†å¤‡è®­ç»ƒæ•°æ®é›†ã€‚éœ€è¦å°†**æ•°æ®æ ¼å¼åŒ–**ä»¥åŒ…å«`instruction`ã€`output`å­—æ®µã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªè„šæœ¬ [convert_func.py](./ie2instruction/convert_func.py)ï¼Œå®ƒå¯ä»¥å°†æ•°æ®æ‰¹é‡è½¬æ¢æˆæ¨¡å‹å¯ä»¥ç›´æ¥ä½¿ç”¨çš„æ ¼å¼ã€‚

2. å…¶æ¬¡ï¼Œé€æ­¥æµ‹è¯•æ•°æ®é›†ã€‚åœ¨å‡†å¤‡æµ‹è¯•æ•°æ®è½¬æ¢ä¹‹å‰ï¼Œè¯·è®¿é—® [data](./data) ç›®å½•ä»¥äº†è§£å„ä»»åŠ¡æ‰€éœ€çš„æ•°æ®ç»“æ„ï¼š1ï¼‰è¾“å…¥æ•°æ®æ ¼å¼å‚è§ `sample.json`ï¼›2ï¼‰schemaæ ¼å¼è¯·æŸ¥çœ‹ `schema.json`ï¼›3ï¼‰è½¬æ¢åæ•°æ®æ ¼å¼å¯å‚ç…§ `train.json`ã€‚**ä¸è®­ç»ƒæ•°æ®ä¸åŒ, æµ‹è¯•æ•°æ®çš„è¾“å…¥æ— éœ€åŒ…å«æ ‡æ³¨å­—æ®µï¼ˆ`entity`, `relation`, `event`ï¼‰**ã€‚

ä½¿ç”¨è¿™ä¸ªå‘½ä»¤è¿›è¡Œæ•°æ®è½¬æ¢ï¼ˆéœ€è¦è‡ªå·±ä¿®æ”¹yamlå‚æ•°è°ƒæ•´æ˜¯**è®­ç»ƒæ•°æ®é›†**å’Œ**æµ‹è¯•æ•°æ®é›†**ï¼Œä»¥åŠå…¶ä»–å‚æ•°ï¼‰


```
python instruction/convert_func.py
```

éœ€è¦è‡ªå·±ä¿®æ”¹**é…ç½®æˆ–å‚æ•°**ï¼š[convert.yaml](./examples/infer/convert.yaml)

å‚æ•°è¯´æ˜ï¼š

|     å­—æ®µ     |                             è¯´æ˜                             |
| :----------: | :----------------------------------------------------------: |
|     mode     |           æ˜¯ç”¨æˆ·è‡ªå·±é€‰æ‹©ç”Ÿæˆè®­ç»ƒæ•°æ®è¿˜æ˜¯æµ‹è¯•æ•°æ®ã€‚           |
|   src_path   |              æ˜¯æ ·ä¾‹ï¼Œå³æè¿°äº†è½¬æ¢å‰æ•°æ®çš„æ ¼å¼ã€‚              |
|   tgt_path   | æ˜¯è½¬æ¢åçš„æ•°æ®ã€‚**æµ‹è¯•ä¸è®­ç»ƒæ•°æ®ä¸åŒ, æµ‹è¯•æ•°æ®çš„è¾“å…¥æ— éœ€åŒ…å«æ ‡æ³¨å­—æ®µï¼ˆ`entity`, `relation`, `event`ï¼‰**ã€‚ |
|   language   |     æ”¯æŒ`zh`, `en`ä¸¤ç§è¯­è¨€, ä¸åŒè¯­è¨€ä½¿ç”¨çš„æŒ‡ä»¤æ¨¡ç‰ˆä¸åŒã€‚     |
|     task     | ç›®å‰æ”¯æŒ['`RE`', '`NER`', '`EE`', '`EET`', '`EEA`', 'KG']ä»»åŠ¡ã€‚ |
|  split_num   | å®šä¹‰å•ä¸ªæŒ‡ä»¤ä¸­å¯åŒ…å«çš„æœ€å¤§schemaæ•°ç›®ã€‚é»˜è®¤å€¼ä¸º4ï¼Œè®¾ç½®ä¸º-1åˆ™ä¸è¿›è¡Œåˆ‡åˆ†ã€‚æ¨èçš„ä»»åŠ¡åˆ‡åˆ†æ•°é‡ä¾ä»»åŠ¡è€Œå¼‚ï¼š**NERå»ºè®®ä¸º6ï¼ŒREã€EEã€EETã€EEAå‡æ¨èä¸º4ã€KGæ¨èä¸º1**ã€‚ |
| random_sort  | æ˜¯å¦å¯¹æŒ‡ä»¤ä¸­çš„schemaéšæœºæ’åº, é»˜è®¤ä¸ºFalse, å³æŒ‰å­—æ¯é¡ºåºæ’åºã€‚ |
| split (å¿…é€‰) | æŒ‡å®šæ•°æ®é›†ç±»å‹ï¼Œ`train` (è®­ç»ƒé›†train.jsonã€éªŒè¯é›†dev.jsonå‡ä½¿ç”¨`train`) æˆ–`test`ã€‚è®¾ç½® `split` ä¸º **test** æ—¶ï¼Œè¯·æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©é€‚å½“çš„schemaæ•°é‡ï¼š**NERæ¨èä¸º6ï¼Œè€ŒREã€EEã€EETã€EEAæ¨èä¸º4**ã€‚ |

* è½¬æ¢åçš„è®­ç»ƒæ•°æ®å°†åŒ…å« `task`, `source`, `instruction`, `output` å››ä¸ªå­—æ®µã€‚
* è½¬æ¢åçš„æµ‹è¯•æ•°æ®å°†å«æœ‰`id`, `task`, `source`, `instruction`, `label`äº”ä¸ªå­—æ®µã€‚`label` å­—æ®µå°†ç”¨äºåç»­è¯„ä¼°ã€‚è‹¥è¾“å…¥æ•°æ®ä¸­ç¼ºå°‘æ ‡æ³¨å­—æ®µï¼ˆ`entity`, `relation`, `event`ï¼‰ï¼Œåˆ™è½¬æ¢åçš„æµ‹è¯•æ•°æ®å°†ä¸åŒ…å«`label`å­—æ®µï¼Œé€‚ç”¨äºé‚£äº›æ— åŸå§‹æ ‡æ³¨æ•°æ®çš„åœºæ™¯ã€‚

##  ğŸ§­ å¾®è°ƒ

é»˜è®¤æ–¹å¼æ˜¯ Lora å¾®è°ƒã€‚

ä¸‹é¢æ˜¯ä¸€äº›å·²ç»ç»è¿‡å……åˆ†ä¿¡æ¯æŠ½å–æŒ‡ä»¤æ•°æ®è®­ç»ƒçš„æ¨¡å‹ï¼š

| æ¨¡å‹                      | ä¸‹è½½                                                         | æè¿°                             |
| ------------------------- | ------------------------------------------------------------ | -------------------------------- |
| llama2-13b-iepile-lora    | [huggingface](https://huggingface.co/zjunlp/llama2-13b-iepile-lora/tree/main) | ï¼ˆåº•åº§æ¨¡å‹æ˜¯LLaMA2-13B-Chatï¼‰    |
| baichuan2-13b-iepile-lora | [huggingface](https://huggingface.co/zjunlp/baichuan2-13b-iepile-lora) | ï¼ˆåº•åº§æ¨¡å‹æ˜¯BaiChuan2-13B-Chatï¼‰ |
| llama3-8b-iepile-lora     | [huggingface](https://huggingface.co/zjunlp/llama3-8b-iepile-lora) |                                  |
| qwen1.5-14b-iepile-lora   | [huggingface](https://huggingface.co/zjunlp/qwen1.5-14b-iepile-lora) |                                  |
| OneKE                     | [huggingface](https://huggingface.co/zjunlp/OneKE)           |                                  |

é¦–å…ˆéœ€è¦ç¡®å®šçš„æ˜¯å¤šå¡è¿˜æ˜¯å•å¡è®­ç»ƒï¼Œæ£€æŸ¥å½“å‰GPUæ•°é‡ï¼š

```bash
nvidia-smi -L
```

è®¾ç½®è®­ç»ƒç”¨å¡ï¼š

```bash
CUDA_VISIBLE_DEVICES="0"  # CUDA_VISIBLE_DEVICES="0,1,2,3"
```

å…ˆåˆ›å»ºæ–‡ä»¶å¤¹ç”¨äºå­˜æ”¾å¾®è°ƒç»“æœï¼š

```bash
output_dir='lora/llama2-13b-chat-v1'
mkdir -p ${output_dir}
```

å†è¿è¡Œè„šæœ¬ï¼š

```bash
python run.py --mood lora
```

[é…ç½®å‚æ•°](./examples/infer/fine_llama.yaml)ï¼š

```bash
do_train: true
do_eval: true
overwrite_output_dir: true
model_name_or_path: 'models/llama2-13B-Chat'
stage: 'sft'
model_name: 'llama'
template: 'llama2'
train_file: 'data/train.json'
valid_file: 'data/dev.json'
output_dir: '${output_dir}'
per_device_train_batch_size: 2
per_device_eval_batch_size: 2
gradient_accumulation_steps: 4
preprocessing_num_workers: 16
num_train_epochs: 10
learning_rate: 5e-5
max_grad_norm: 0.5
optim: 'adamw_torch'
max_source_length: 400
cutoff_len: 700
max_target_length: 300
evaluation_strategy: 'epoch'
save_strategy: 'epoch'
save_total_limit: 10
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05
bf16: true
bits: 4
```

å‚æ•°è¯´æ˜ï¼š

| å­—æ®µ                                                    | æè¿°                                                         |
| ------------------------------------------------------- | ------------------------------------------------------------ |
| model_name                                              | æŒ‡å®šæ‰€éœ€çš„**æ¨¡å‹æ¶æ„åç§°**(7Bã€13Bã€Baseã€Chatå±äºåŒä¸€æ¨¡å‹æ¶æ„)ã€‚å½“å‰æ”¯æŒçš„æ¨¡å‹åŒ…æ‹¬ï¼š["`llama`", "`alpaca`", "`vicuna`", "`zhixi`", "`falcon`", "`baichuan`", "`chatglm`", "`qwen`", "`moss`", "`openba`"]ã€‚**è¯·æ³¨æ„**ï¼Œæ­¤å‚æ•°åº”ä¸ `--model_name_or_path` åŒºåˆ†ã€‚ |
| model_name_or_path                                      | æ¨¡å‹è·¯å¾„, è¯·åˆ° [HuggingFace](https://huggingface.co/models) ä¸‹è½½ç›¸åº”æ¨¡å‹ã€‚ |
| template                                                | ä½¿ç”¨çš„**æ¨¡æ¿åç§°**ï¼ŒåŒ…æ‹¬ï¼š`alpaca`, `baichuan`, `baichuan2`, `chatglm3`ç­‰, è¯·å‚è€ƒ [src/datamodule/template.py](./src/datamodule/template.py) æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„æ¨¡ç‰ˆåç§°, é»˜è®¤ä½¿ç”¨çš„æ˜¯`alpaca`æ¨¡æ¿, **`Chat`ç‰ˆæœ¬çš„æ¨¡å‹å»ºè®®ä½¿ç”¨é…å¥—çš„æ¨¡ç‰ˆ, Baseç‰ˆæœ¬æ¨¡å‹å¯é»˜è®¤ä½¿ç”¨`alpaca`**ã€‚ |
| train_file, valid_fileï¼ˆå¯é€‰ï¼‰                          | è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„**æ–‡ä»¶è·¯å¾„**ã€‚æ³¨æ„ï¼šç›®å‰ä»…æ”¯æŒjsonæ ¼å¼çš„æ–‡ä»¶ã€‚`valid_file`ä¸èƒ½æŒ‡å®šä¸º`test.json`æ–‡ä»¶(ä¸åŒ…å«outputå­—æ®µ,ä¼šæŠ¥é”™)ï¼Œå¯ä»¥é€šè¿‡æŒ‡å®š`val_set_size`å‚æ•°æ›¿ä»£`valid_file`ã€‚ |
| output_dir                                              | LoRAå¾®è°ƒåçš„**æƒé‡å‚æ•°ä¿å­˜è·¯å¾„**ã€‚                           |
| val_set_size                                            | **éªŒè¯é›†çš„æ ·æœ¬æ•°é‡**, é»˜è®¤ä¸º1000ã€‚è‹¥æ²¡æœ‰æŒ‡å®š`valid_file`, å°†ä¼šä»`train_file`ä¸­åˆ’åˆ†å‡ºå¯¹åº”æ•°é‡çš„æ ·æœ¬ä½œä¸ºéªŒè¯é›†ã€‚ |
| per_device_train_batch_size, per_device_eval_batch_size | æ¯å°GPUè®¾å¤‡ä¸Šçš„`batch_size`, æ ¹æ®æ˜¾å­˜å¤§å°è°ƒæ•´, RTX3090å»ºè®®è®¾ç½®2~4ã€‚ |
| max_source_length, max_target_length, cutoff_len        | æœ€å¤§è¾“å…¥ã€è¾“å‡ºé•¿åº¦ã€æˆªæ–­é•¿åº¦, æˆªæ–­é•¿åº¦å¯ä»¥ç®€å•åœ°è§†ä½œæœ€å¤§è¾“å…¥é•¿åº¦ + æœ€å¤§è¾“å‡ºé•¿åº¦, éœ€æ ¹æ®å…·ä½“éœ€æ±‚å’Œæ˜¾å­˜å¤§å°è®¾ç½®åˆé€‚å€¼ã€‚ |
| deepspeed ï¼ˆå¯é€‰ï¼‰                                      | ä½¿ç”¨`deepspeed`, å¯è®¾ç½® `--deeepspeed data/DeepSpeed/ds_config_bf16_stage2.json`ã€‚å¯é€šè¿‡è®¾ç½® `bits` = 4 è¿›è¡Œé‡åŒ–, RTX3090å»ºè®®é‡åŒ–ã€‚ |

* è¦äº†è§£æ›´å¤šå…³äº**å‚æ•°é…ç½®**çš„ä¿¡æ¯ï¼Œè¯·å‚è€ƒ [src/args](./src/args) ç›®å½•ã€‚

## â›³ æ¨ç†

### åŸºç¡€æ¨¡å‹+Lora

ä»¥ä¸‹æ˜¯ä¸€äº›ç»è¿‡LoRAæŠ€æœ¯è®­ç»ƒä¼˜åŒ–çš„æ¨¡å‹(**Loraæƒé‡**)ï¼š

<details>
  <summary><b>V1ç‰ˆæœ¬</b></summary>

* [alpaca-7b-lora-ie](https://huggingface.co/zjunlp/alpaca-7b-lora-ie)
* [llama-7b-lora-ie](https://huggingface.co/zjunlp/llama-7b-lora-ie)
* [alpaca-13b-lora-ie](https://huggingface.co/zjunlp/alpaca-13b-lora-ie)
* [knowlm-13b-ie-lora](https://huggingface.co/zjunlp/knowlm-13b-ie-lora)


| checkpoint_dir     | model_name_or_path          | moadel_name | fp16/bf16 | template |
| ------------------ | --------------------------- | ----------- | --------- | -------- |
| llama-7b-lora-ie   | llama-7b                    | llama       | fp16      | alpaca   |
| alpaca-7b-lora-ie  | alpaca-7b                   | alpaca      | fp16      | alpaca   |
| knowlm-13b-ie-lora | zjunlp/knowlm-13b-base-v1.0 | zhixi       | fp16      | alpaca   |

</details>

**V2ç‰ˆæœ¬(æ¨è)**

* [zjunlp/llama2-13b-iepile-lora](https://huggingface.co/zjunlp/llama2-13b-iepile-lora/tree/main)
* [zjunlp/baichuan2-13b-iepile-lora](https://huggingface.co/zjunlp/baichuan2-13b-iepile-lora)
* [zjunlp/llama3-8b-iepile-lora](https://huggingface.co/zjunlp/llama3-8b-iepile-lora)
* [zjunlp/qwen1.5-14b-iepile-lora](https://huggingface.co/zjunlp/qwen1.5-14b-iepile-lora)


| checkpoint_dir            | model_name_or_path | moadel_name | fp16/bf16 | template  |
| ------------------------- | ------------------ | ----------- | --------- | --------- |
| llama2-13b-iepile-lora    | LLaMA2-13B-Chat    | llama       | bf16      | llama2    |
| baichuan2-13b-iepile-lora | BaiChuan2-13B-Chat | baichuan    | bf16      | baichuan2 |
| llama3-8b-iepile-lora     | LLaMA3-8B-Instruct | llama       | bf16      | alpaca    |
| qwen1.5-14b-iepile-lora   | Qwen1.5-14B-Chat   | qwen2       | bf16      | qwen      |



è¦ä½¿ç”¨è¿™äº›**è®­ç»ƒå¥½çš„**LoRAæ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œå¯ä»¥æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
python run.py --mood infer
```

[é…ç½®å‚è€ƒ](./examples/infer/infer_llama.yaml)ï¼š

```yaml
stage: sft
model_name_or_path: 'models/llama2-13B-Chat'
checkpoint_dir: 'lora/llama2-13b-IEPile-lora'
model_name: 'llama'
template: 'llama2'
do_predict: true
input_file: 'data/input.json'
output_file: 'results/llama2-13b-IEPile-lora_output.json'
finetuning_type: 'lora'
output_dir: 'lora/test'
predict_with_generate: true
cutoff_len: 512
bf16: true
max_new_tokens: 300
bits: 4
```

å‚æ•°è¯´æ˜ï¼š

| å­—æ®µ                       | è¯´æ˜                                                         |
| -------------------------- | ------------------------------------------------------------ |
| model_name_or_path         | æŒ‡å®šæ‰€ä½¿ç”¨çš„åŸºç¡€æ¨¡å‹è·¯å¾„ï¼Œå¿…é¡»ä¸ç›¸åº”çš„LoRAæ¨¡å‹åŒ¹é…ã€‚         |
| checkpoint_dir             | LoRAçš„æƒé‡æ–‡ä»¶è·¯å¾„ã€‚                                         |
| output_dir                 | æ­¤å‚æ•°åœ¨æ¨ç†æ—¶ä¸èµ·ä½œç”¨ï¼Œå¯ä»¥éšæ„æŒ‡å®šä¸€ä¸ªè·¯å¾„ã€‚               |
| input_file, output_file    | åˆ†åˆ«æŒ‡å®šè¾“å…¥çš„æµ‹è¯•æ–‡ä»¶è·¯å¾„å’Œé¢„æµ‹ç»“æœçš„è¾“å‡ºæ–‡ä»¶è·¯å¾„ã€‚         |
| cutoff_len, max_new_tokens | è®¾ç½®æœ€å¤§çš„è¾“å…¥é•¿åº¦å’Œç”Ÿæˆçš„æ–°tokenæ•°é‡ï¼Œæ ¹æ®æ˜¾å­˜å¤§å°è¿›è¡Œè°ƒæ•´ã€‚ |
| bits                       | å¯é€šè¿‡è®¾ç½® `bits` = 4 è¿›è¡Œé‡åŒ–, RTX3090å»ºè®®é‡åŒ–ã€‚            |

* åœ¨è¿›è¡Œæ¨ç†æ—¶ï¼Œ`model_name`, `template`, å’Œ `bf16` å¿…é¡»ä¸è®­ç»ƒæ—¶çš„è®¾ç½®ç›¸åŒã€‚

### IEä¸“ç”¨æ¨¡å‹

| checkpoint_dir | model_name_or_path | moadel_name | fp16/bf16 | template  |
| -------------- | ------------------ | ----------- | --------- | --------- |
| OneKE          | OneKE              | llama       | bf16      | llama2_zh |

**`OneKE(based on chinese-alpaca2)`** æ¨¡å‹ä¸‹è½½é“¾æ¥ï¼š[zjunlp/OneKE](https://huggingface.co/zjunlp/OneKE)

æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
python run.py --mood infer
```


è‹¥è¦ä½¿ç”¨**å·²è®­ç»ƒçš„æ¨¡å‹**ï¼ˆæ— LoRAæˆ–LoRAå·²é›†æˆåˆ°æ¨¡å‹å‚æ•°ä¸­ï¼‰ï¼Œå¯ä»¥æ”¹ä¸ºä»¥ä¸‹é…ç½®è¿›è¡Œé¢„æµ‹ï¼š

```yaml
stage: sft
model_name_or_path: 'models/OneKE'
model_name: 'llama'
template: 'llama2_zh'
do_predict: true
input_file: 'data/input.json'
output_file: 'results/OneKE_output.json'
output_dir: 'lora/test'
predict_with_generate: true
cutoff_len: 512
bf16: true
max_new_tokens: 300
bits: 4
```

`model_name_or_path`: IEä¸“ç”¨æ¨¡å‹æƒé‡è·¯å¾„

æ³¨æ„ï¼šå¯¹äºå·²ç»é‡åŒ–çš„æ¨¡å‹ï¼ˆå¦‚ 4-bit æˆ– 8-bitï¼‰ï¼Œä¸éœ€è¦å†è°ƒç”¨ `.to()` æ¥è½¬æ¢è®¾å¤‡æˆ–æ•°æ®ç±»å‹ï¼Œå› ä¸ºé‡åŒ–æ¨¡å‹å·²ç»é¢„å…ˆè®¾ç½®å¥½äº†è¿™äº›ä¿¡æ¯ã€‚

### åˆå¹¶åŸºç¡€æ¨¡å‹+Loraå¯¼å‡º

è¿è¡Œå‘½ä»¤ï¼š

```bash
python run.py --mood export
```

å°†åº•åº§æ¨¡å‹å’Œè®­ç»ƒçš„Loraæƒé‡åˆå¹¶, å¯¼å‡ºæ¨¡å‹

[é…ç½®æ–‡ä»¶](./examples/infer/export.yaml)ï¼š

```yaml
model_name_or_path: 'models/Baichuan2-13B-Chat'
checkpoint_dir: 'lora_results/baichuan2-13b-v1/checkpoint-xxx'
export_dir: 'lora_results/baichuan2-13b-v1/baichuan2-13b-v1'
stage: 'sft'
model_name: 'baichuan'
template: 'baichuan2'
output_dir: 'lora_results/test'
```

æ³¨æ„ `template`ã€`model_name` ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ã€‚


### vllmåŠ é€Ÿæ¨ç†

æ¨èç¯å¢ƒï¼š

```bash
pip install tiktoken
pip install peft==0.7.1
pip install transformers==4.41.2

pip install vllm==0.3.0
pip install jinja2==3.0.1
pip install pydantic==1.9.2

ip route add 8.8.8.8 via 127.0.0.1
```

è¿è¡Œè„šæœ¬

```bash
Â python run.py --mood infer_vllm
```

[å‚è€ƒé…ç½® vllm_baichuan.yaml](./examples/infer/infer_baichuan_vllm.yaml):

```yaml
stage: sft
model_name_or_path: 'lora_results/baichuan2-13b-v1/baichuan2-13b-v1'
model_name: 'baichuan'
template: 'baichuan2'
do_predict: true
input_file: 'data/input.json'
output_file: 'results/baichuan2-13b-IEPile-lora_output.json'
output_dir: 'lora_results/test'
batch_size: 4
predict_with_generate: true
max_source_length: 1024
bf16: true
max_new_tokens: 512
```




## ğŸ§¾ è¯„ä¼°

æˆ‘ä»¬æä¾›äº†è¯„ä¼°å„ä¸ªä»»åŠ¡F1åˆ†æ•°çš„è„šæœ¬ã€‚

```bash
python run.py -m evaluate
```

[é…ç½®æ–‡ä»¶](./examples/infer/evaluate.yaml)ï¼š

```bash
path1: "results/baichuan2-13b-iepile-lora_output.json"
task: "RE"
language: "zh"
sort_by: "source"
match_mode: "normal"
metrics_list: "f1"
```

å‚æ•°è¯´æ˜ï¼š

* `path1` æ˜¯æ¨¡å‹çš„è¾“å‡ºæ–‡ä»¶, å…¶ä¸­ä¸€æ¡æ•°æ®æ ·æœ¬å¦‚ä¸‹æ‰€ç¤º, ç»æµ‹è¯•æ•°æ®è½¬æ¢è„šæœ¬è½¬æ¢åçš„æ•°æ®(`test.json`)å…·æœ‰`id`ã€`instruction`ã€`label`å­—æ®µ, `output`å­—æ®µæ˜¯ç»è¿‡æ¨¡å‹é¢„æµ‹è„šæœ¬åçš„æ¨¡å‹çœŸå®è¾“å‡ºã€‚

* `task`: ç›®å‰æ”¯æŒ['RE', 'NER', 'EE', 'EET', 'EEA']äº”ç±»ä»»åŠ¡ã€‚
* å¯ä»¥è®¾ç½® `sort_by` ä¸º `source`, åˆ†åˆ«è®¡ç®—æ¯ä¸ªæ•°æ®é›†ä¸Šçš„F1åˆ†æ•°ã€‚

-------

âœ¨
