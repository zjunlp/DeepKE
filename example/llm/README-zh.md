# å¾®è°ƒ

## ğŸ¯ 1.ä»»åŠ¡ç›®æ ‡

æˆ‘ä»¬å°†`Instruction-based KGC`åˆ¶å®šä¸ºä¸€ç§éµå¾ªæŒ‡ä»¤çš„è‡ªå›å½’ç”Ÿæˆä»»åŠ¡ã€‚æ¨¡å‹é¦–å…ˆéœ€è¦ç†è§£æŒ‡ä»¤è¯†åˆ«å…¶æ„å›¾ï¼Œç„¶åæ ¹æ®æŒ‡ä»¤å†…å®¹ï¼Œæ¨¡å‹ä¼šåŸºäºè¾“å…¥çš„æ–‡æœ¬æŠ½å–ç›¸åº”çš„ä¸‰å…ƒç»„å¹¶ä»¥æŒ‡å®šçš„æ ¼å¼è¾“å‡ºã€‚æœ¬æ–‡çš„ **`instruction`** æ ¼å¼é‡‡çº³äº†ç±»JSONå­—ç¬¦ä¸²çš„ç»“æ„ï¼Œå®è´¨ä¸Šæ˜¯ä¸€ç§å­—å…¸å‹å­—ç¬¦ä¸²ã€‚å®ƒç”±ä»¥ä¸‹ä¸‰ä¸ªå­—æ®µæ„æˆï¼š
(1) **`'instruction'`**ï¼Œå³ä»»åŠ¡æè¿°ï¼Œä»¥è‡ªç„¶è¯­è¨€æŒ‡å®šæ¨¡å‹æ‰®æ¼”çš„è§’è‰²ä»¥åŠéœ€è¦å®Œæˆçš„ä»»åŠ¡ï¼›
(2) **`'schema'`**ï¼Œè¿™æ˜¯ä¸€ä»½éœ€æå–çš„æ ‡ç­¾åˆ—è¡¨ï¼Œæ˜ç¡®æŒ‡å‡ºäº†å¾…æŠ½å–ä¿¡æ¯çš„å…³é”®å­—æ®µï¼Œååº”ç”¨æˆ·çš„éœ€æ±‚ï¼Œæ˜¯åŠ¨æ€å¯å˜çš„ï¼›
(3) **`'input'`**ï¼ŒæŒ‡çš„æ˜¯ç”¨äºä¿¡æ¯æŠ½å–çš„æºæ–‡æœ¬ã€‚


ä»¥ä¸‹æ˜¯ä¸€æ¡**æ•°æ®å®ä¾‹**ï¼š

```json
{
  "instruction": "{\"instruction\": \"ä½ æ˜¯ä¸“é—¨è¿›è¡Œå®ä½“æŠ½å–çš„ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„å®ä½“ï¼Œä¸å­˜åœ¨çš„å®ä½“ç±»å‹è¿”å›ç©ºåˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚\", \"schema\": [\"ç»„ç»‡æœºæ„\", \"åœ°ç†ä½ç½®\", \"äººç‰©\"], \"input\": \"å¯¹äºåº·æœ‰ä¸ºã€æ¢å¯è¶…ã€è°­å—£åŒã€ä¸¥å¤è¿™äº›ä»æ—§æ–‡åŒ–è¥å’ä¸­èµ°æ¥çš„å¹´è½»â€œå¸ƒè¡£â€ï¼Œä»–ä»¬èƒŒè´Ÿç€æ²‰é‡çš„å†å²åŒ…è¢±ï¼Œèƒ½å¤ŸæŒ£è„±æ—§ä¼ ç»Ÿçš„æŸç¼šï¼Œä¸ºæ‹¯æ•‘æ°‘æ—çš„å±äº¡è€ŒçŒ®èº«ï¼Œå®åœ¨æ˜¯ä¸­åæ°‘æ—çš„è„Šæ¢ã€‚\"}",
  "output": "{\"ç»„ç»‡æœºæ„\": [], \"åœ°ç†ä½ç½®\": [\"ä¸­å\"], \"äººç‰©\": [\"åº·æœ‰ä¸º\", \"æ¢å¯è¶…\", \"è°­å—£åŒ\", \"ä¸¥å¤\"]}"
}
```

å¾…æŠ½å–çš„schemaåˆ—è¡¨æ˜¯ ["ç»„ç»‡æœºæ„", "åœ°ç†ä½ç½®", "äººç‰©"], å¾…æŠ½å–çš„æ–‡æœ¬æ˜¯"*å¯¹äºåº·æœ‰ä¸ºã€æ¢å¯è¶…ã€è°­å—£åŒã€ä¸¥å¤è¿™äº›ä»æ—§æ–‡åŒ–è¥å’ä¸­èµ°æ¥çš„å¹´è½»â€œå¸ƒè¡£â€ï¼Œä»–ä»¬èƒŒè´Ÿç€æ²‰é‡çš„å†å²åŒ…è¢±ï¼Œèƒ½å¤ŸæŒ£è„±æ—§ä¼ ç»Ÿçš„æŸç¼šï¼Œä¸ºæ‹¯æ•‘æ°‘æ—çš„å±äº¡è€ŒçŒ®èº«ï¼Œå®åœ¨æ˜¯ä¸­åæ°‘æ—çš„è„Šæ¢ã€‚*", è¾“å‡ºæ˜¯ `{"ç»„ç»‡æœºæ„": [], "åœ°ç†ä½ç½®": ["ä¸­å"], "äººç‰©": ["åº·æœ‰ä¸º", "æ¢å¯è¶…", "è°­å—£åŒ", "ä¸¥å¤"]}`

> æ³¨æ„è¾“å‡ºä¸­çš„ schema é¡ºåºä¸ instruction ä¸­çš„ schema é¡ºåºä¸€è‡´


<details>
  <summary><b>æ›´å¤šä»»åŠ¡çš„æ•°æ®å®ä¾‹</b></summary>


```json
{
  "instruction": "{\"instruction\": \"ä½ æ˜¯ä¸“é—¨è¿›è¡Œå…³ç³»æŠ½å–çš„ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„å…³ç³»ä¸‰å…ƒç»„ï¼Œä¸å­˜åœ¨çš„å…³ç³»è¿”å›ç©ºåˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚\", \"schema\": [\"å›½ç±\", \"ä½œè€…\", \"æ¯•ä¸šé™¢æ ¡\", \"ä¸»è§’\"], \"input\": \"å¯¹æ¯”æ—¥æœ¬åŠ¨ç”»ç”µå½±åœ¨ä¸­æ—¥ä¸¤å›½çš„ç¥¨æˆ¿è¡¨ç°ï¼Œå¯ä»¥å‘ç°ï¼Œæ—¥æ¼«é£æ ¼çš„åŠ¨ç”»ï¼Œåœ¨å›½å†…ä¹Ÿæœ‰åœˆå±‚é™åˆ¶ï¼Œå³ä¾¿æ˜¯å®«å´éªã€Šåƒä¸åƒå¯»ã€‹ã€æ–°æµ·è¯šã€Šä½ çš„åå­—ã€‹ï¼Œè¿™ç±»æ—¥æœ¬åŠ¨ç”»ç¥¨æˆ¿æ¦œé¦–çš„ç”µå½±ï¼Œå›½å†…ç¥¨æˆ¿ä¹Ÿåœç•™åœ¨5äº¿å·¦å³\"}",
  "output": "{\"å›½ç±\": [], \"ä½œè€…\": [{\"subject\": \"ä½ çš„åå­—\", \"object\": \"æ–°æµ·è¯š\"}], \"æ¯•ä¸šé™¢æ ¡\": [], \"ä¸»è§’\": []}"
}

{
  "instruction": "{\"instruction\": \"ä½ æ˜¯ä¸“é—¨è¿›è¡Œäº‹ä»¶æå–çš„ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„äº‹ä»¶ï¼Œä¸å­˜åœ¨çš„äº‹ä»¶è¿”å›ç©ºåˆ—è¡¨ï¼Œä¸å­˜åœ¨çš„è®ºå…ƒè¿”å›NANï¼Œå¦‚æœè®ºå…ƒå­˜åœ¨å¤šå€¼è¯·è¿”å›åˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚\", \"schema\": [{\"event_type\": \"äººç”Ÿ-æ±‚å©š\", \"trigger\": true, \"arguments\": [\"æ±‚å©šå¯¹è±¡\"]}, {\"event_type\": \"äººç”Ÿ-è®¢å©š\", \"trigger\": true, \"arguments\": [\"è®¢å©šä¸»ä½“\", \"æ—¶é—´\"]}, {\"event_type\": \"ç¾å®³/æ„å¤–-å/å®å¡Œ\", \"trigger\": true, \"arguments\": [\"å—ä¼¤äººæ•°\", \"åå¡Œä¸»ä½“\"]}, {\"event_type\": \"äººç”Ÿ-å¤±è”\", \"trigger\": true, \"arguments\": [\"åœ°ç‚¹\", \"å¤±è”è€…\"]}], \"input\": \"éƒ­ç¢§å©·è®¢å©šåï¼Œå¡«èµ„æ–™ä¾æ—§æƒ³è¦å¡«å•èº«ï¼Œæœ‰è°æ³¨æ„å‘ä½è¯´äº†ä»€ä¹ˆï¼Ÿ\"}",
  "output": "{\"äººç”Ÿ-æ±‚å©š\": [], \"äººç”Ÿ-è®¢å©š\": [{\"trigger\": \"è®¢å©š\", \"arguments\": {\"è®¢å©šä¸»ä½“\": [\"å‘ä½\", \"éƒ­ç¢§å©·\"], \"æ—¶é—´\": \"NAN\"}}], \"ç¾å®³/æ„å¤–-å/å®å¡Œ\": [], \"äººç”Ÿ-å¤±è”\": []}"
}
```

</details>

[instruction.py](./ie2instruction/convert/utils/instruction.py) ä¸­æä¾›äº†å„ä¸ªä»»åŠ¡çš„æŒ‡ä»¤æ¨¡ç‰ˆã€‚



> **æ³¨æ„**âš ï¸: è€ç‰ˆçš„æ•°æ®æ ·å¼è¯·å‚è€ƒ[kg2instruction/README.md](./kg2instruction/README.md)



## ğŸ“Š 2.æ•°æ®


### 2.1ç°æœ‰æ•°æ®é›†

| åç§°       | ä¸‹è½½                                                         | æ•°é‡  | æè¿°                                                         |
| ---------- | ------------------------------------------------------------ | ----- | ------------------------------------------------------------ |
| InstructIE | [Google drive](https://drive.google.com/file/d/1raf0h98x3GgIhaDyNn1dLle9_HvwD6wT/view?usp=sharing) <br/> [Hugging Face](https://huggingface.co/datasets/zjunlp/InstructIE) <br/> [ModelScope](https://modelscope.cn/datasets/ZJUNLP/InstructIE)<br/> [WiseModel](https://wisemodel.cn/datasets/zjunlp/InstructIE) | 30w+  | **åŒè¯­**(ä¸­æ–‡å’Œè‹±æ–‡)åŸºäºä¸»é¢˜çš„ä¿¡æ¯æŠ½å–(IE)æŒ‡ä»¤æ•°æ®é›†         |
| IEPile     | [Google Drive](https://drive.google.com/file/d/1jPdvXOTTxlAmHkn5XkeaaCFXQkYJk5Ng/view?usp=sharing) <br/> [Hugging Face](https://huggingface.co/datasets/zjunlp/iepile) <br/> [WiseModel](https://wisemodel.cn/datasets/zjunlp/IEPile) <br/> [ModelScpoe](https://modelscope.cn/datasets/ZJUNLP/IEPile) | 200w+ | å¤§è§„æ¨¡(`0.32B` tokens)é«˜è´¨é‡**åŒè¯­**(ä¸­æ–‡å’Œè‹±æ–‡)ä¿¡æ¯æŠ½å–(IE)æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† |


<details>
  <summary><b>InstructIEè¯¦ç»†ä¿¡æ¯</b></summary>
**ä¸€æ¡æ•°æ®çš„ç¤ºä¾‹**


```json
{
  "id": "bac7c32c47fddd20966e4ece5111690c9ce3f4f798c7c9dfff7721f67d0c54a5",
  "cate": "åœ°ç†åœ°åŒº",
  "text": "é˜¿å°”å¤«è¾¾å°”ï¼ˆæŒªå¨è¯­ï¼šAlvdalï¼‰æ˜¯æŒªå¨çš„ä¸€ä¸ªå¸‚é•‡ï¼Œä½äºå†…é™†éƒ¡ï¼Œè¡Œæ”¿ä¸­å¿ƒä¸ºé˜¿å°”å¤«è¾¾å°”æ‘ã€‚å¸‚é•‡é¢ç§¯ä¸º943å¹³æ–¹å…¬é‡Œï¼Œäººå£æ•°é‡ä¸º2,424äººï¼ˆ2018å¹´ï¼‰ï¼Œäººå£å¯†åº¦ä¸ºæ¯å¹³æ–¹å…¬é‡Œ2.6äººã€‚",
  "relation": [
    {"head": "é˜¿å°”å¤«è¾¾å°”", "head_type": "åœ°ç†åœ°åŒº", "relation": "é¢ç§¯", "tail": "943å¹³æ–¹å…¬é‡Œ", "tail_type": "åº¦é‡"},
    {"head": "é˜¿å°”å¤«è¾¾å°”", "head_type": "åœ°ç†åœ°åŒº", "relation": "åˆ«å", "tail": "Alvdal", "tail_type": "åœ°ç†åœ°åŒº"},
    {"head": "å†…é™†éƒ¡", "head_type": "åœ°ç†åœ°åŒº", "relation": "ä½äº", "tail": "æŒªå¨", "tail_type": "åœ°ç†åœ°åŒº"},
    {"head": "é˜¿å°”å¤«è¾¾å°”", "head_type": "åœ°ç†åœ°åŒº", "relation": "ä½äº", "tail": "å†…é™†éƒ¡", "tail_type": "åœ°ç†åœ°åŒº"},
    {"head": "é˜¿å°”å¤«è¾¾å°”", "head_type": "åœ°ç†åœ°åŒº", "relation": "äººå£", "tail": "2,424äºº", "tail_type": "åº¦é‡"}
  ]
}
```

å„å­—æ®µçš„è¯´æ˜:

|   å­—æ®µ   |                             è¯´æ˜                             |
| :------: | :----------------------------------------------------------: |
|    id    |                   æ¯ä¸ªæ•°æ®ç‚¹çš„å”¯ä¸€æ ‡è¯†ç¬¦ã€‚                   |
|   cate   |           æ–‡æœ¬çš„ä¸»é¢˜ç±»åˆ«ï¼Œæ€»è®¡12ç§ä¸åŒçš„ä¸»é¢˜åˆ†ç±»ã€‚           |
|   text   |     æ¨¡å‹çš„è¾“å…¥æ–‡æœ¬ï¼Œç›®æ ‡æ˜¯ä»ä¸­æŠ½å–æ¶‰åŠçš„æ‰€æœ‰å…³ç³»ä¸‰å…ƒç»„ã€‚     |
| relation | æè¿°æ–‡æœ¬ä¸­åŒ…å«çš„å…³ç³»ä¸‰å…ƒç»„ï¼Œå³(head, head_type, relation, tail, tail_type)ã€‚ |

è¯·å‚è€ƒæ•°æ®è½¬æ¢éƒ¨åˆ†ä»£ç ã€‚

</details>


<details>
  <summary><b>IEPileè¯¦ç»†ä¿¡æ¯</b></summary>



`IEPile` ä¸­çš„æ¯æ¡æ•°æ®å‡åŒ…å« `task`, `source`, `instruction`, `output` 4ä¸ªå­—æ®µ, ä»¥ä¸‹æ˜¯å„å­—æ®µçš„è¯´æ˜

|    å­—æ®µ     |                             è¯´æ˜                             |
| :---------: | :----------------------------------------------------------: |
|    task     | è¯¥å®ä¾‹æ‰€å±çš„ä»»åŠ¡, (`NER`ã€`RE`ã€`EE`ã€`EET`ã€`EEA`) 5ç§ä»»åŠ¡ä¹‹ä¸€ã€‚ |
|   source    |                      è¯¥å®ä¾‹æ‰€å±çš„æ•°æ®é›†                      |
| instruction | è¾“å…¥æ¨¡å‹çš„æŒ‡ä»¤, ç»è¿‡json.dumpså¤„ç†æˆJSONå­—ç¬¦ä¸², åŒ…æ‹¬`"instruction"`, `"schema"`, `"input"`ä¸‰ä¸ªå­—æ®µ |
|   output    | è¾“å‡º, é‡‡ç”¨å­—å…¸çš„jsonå­—ç¬¦ä¸²çš„æ ¼å¼, keyæ˜¯schema, valueæ˜¯æŠ½å–å‡ºçš„å†…å®¹ |


åœ¨`IEPile`ä¸­, **`instruction`** çš„æ ¼å¼é‡‡çº³äº†ç±»JSONå­—ç¬¦ä¸²çš„ç»“æ„ï¼Œå®è´¨ä¸Šæ˜¯ä¸€ç§å­—å…¸å‹å­—ç¬¦ä¸²ï¼Œå®ƒç”±ä»¥ä¸‹ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†æ„æˆï¼š
(1) **`'instruction'`**: ä»»åŠ¡æè¿°, å®ƒæ¦‚è¿°äº†æŒ‡ä»¤çš„æ‰§è¡Œä»»åŠ¡(`NER`ã€`RE`ã€`EE`ã€`EET`ã€`EEA`ä¹‹ä¸€)ã€‚
(2) **`'schema'`**: å¾…æŠ½å–çš„schema(`å®ä½“ç±»å‹`, `å…³ç³»ç±»å‹`, `äº‹ä»¶ç±»å‹`)åˆ—è¡¨ã€‚
(3) **`'input'`**: å¾…æŠ½å–çš„æ–‡æœ¬ã€‚


ä»¥ä¸‹æ˜¯ä¸€æ¡**æ•°æ®å®ä¾‹**ï¼š

```json
{
  "task": "NER",
  "source": "MSRA",
  "instruction": "{\"instruction\": \"ä½ æ˜¯ä¸“é—¨è¿›è¡Œå®ä½“æŠ½å–çš„ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„å®ä½“ï¼Œä¸å­˜åœ¨çš„å®ä½“ç±»å‹è¿”å›ç©ºåˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚\", \"schema\": [\"ç»„ç»‡æœºæ„\", \"åœ°ç†ä½ç½®\", \"äººç‰©\"], \"input\": \"å¯¹äºåº·æœ‰ä¸ºã€æ¢å¯è¶…ã€è°­å—£åŒã€ä¸¥å¤è¿™äº›ä»æ—§æ–‡åŒ–è¥å’ä¸­èµ°æ¥çš„å¹´è½»â€œå¸ƒè¡£â€ï¼Œä»–ä»¬èƒŒè´Ÿç€æ²‰é‡çš„å†å²åŒ…è¢±ï¼Œèƒ½å¤ŸæŒ£è„±æ—§ä¼ ç»Ÿçš„æŸç¼šï¼Œä¸ºæ‹¯æ•‘æ°‘æ—çš„å±äº¡è€ŒçŒ®èº«ï¼Œå®åœ¨æ˜¯ä¸­åæ°‘æ—çš„è„Šæ¢ã€‚\"}",
  "output": "{\"ç»„ç»‡æœºæ„\": [], \"åœ°ç†ä½ç½®\": [\"ä¸­å\"], \"äººç‰©\": [\"åº·æœ‰ä¸º\", \"æ¢å¯è¶…\", \"è°­å—£åŒ\", \"ä¸¥å¤\"]}"
}
```

è¯¥æ•°æ®å®ä¾‹æ‰€å±ä»»åŠ¡æ˜¯ `NER`, æ‰€å±æ•°æ®é›†æ˜¯ `MSRA`, å¾…æŠ½å–çš„schemaåˆ—è¡¨æ˜¯ ["ç»„ç»‡æœºæ„", "åœ°ç†ä½ç½®", "äººç‰©"], å¾…æŠ½å–çš„æ–‡æœ¬æ˜¯"*å¯¹äºåº·æœ‰ä¸ºã€æ¢å¯è¶…ã€è°­å—£åŒã€ä¸¥å¤è¿™äº›ä»æ—§æ–‡åŒ–è¥å’ä¸­èµ°æ¥çš„å¹´è½»â€œå¸ƒè¡£â€ï¼Œä»–ä»¬èƒŒè´Ÿç€æ²‰é‡çš„å†å²åŒ…è¢±ï¼Œèƒ½å¤ŸæŒ£è„±æ—§ä¼ ç»Ÿçš„æŸç¼šï¼Œä¸ºæ‹¯æ•‘æ°‘æ—çš„å±äº¡è€ŒçŒ®èº«ï¼Œå®åœ¨æ˜¯ä¸­åæ°‘æ—çš„è„Šæ¢ã€‚*", è¾“å‡ºæ˜¯ `{"ç»„ç»‡æœºæ„": [], "åœ°ç†ä½ç½®": ["ä¸­å"], "äººç‰©": ["åº·æœ‰ä¸º", "æ¢å¯è¶…", "è°­å—£åŒ", "ä¸¥å¤"]}`

**æå‰å‡†å¤‡ï¼š**

æ•°æ®é›†ä¸‹è½½é“¾æ¥ï¼š[Google Drive](https://drive.google.com/file/d/1jPdvXOTTxlAmHkn5XkeaaCFXQkYJk5Ng/view?usp=sharing) | [Hugging Face](https://huggingface.co/datasets/zjunlp/IEPile)ï¼Œå¹¶ç¡®ä¿é¡¹ç›®ç»“æ„å¦‚ä¸‹ï¼š

```
llm
â”œâ”€â”€ train.json    # è®­ç»ƒé›†
â””â”€â”€ dev.json      # éªŒè¯é›†
```

</details>



### 2.2æ•°æ®è½¬æ¢

è¿™é‡Œéœ€è¦å‡†å¤‡**è®­ç»ƒæ•°æ®é›†**å’Œ**æµ‹è¯•æ•°æ®é›†**ã€‚

1. é¦–å…ˆ, å‡†å¤‡è®­ç»ƒæ•°æ®é›†ã€‚éœ€è¦å°†**æ•°æ®æ ¼å¼åŒ–**ä»¥åŒ…å«`instruction`ã€`output`å­—æ®µã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªè„šæœ¬ [convert_func.py](./ie2instruction/convert_func.py)ï¼Œå®ƒå¯ä»¥å°†æ•°æ®æ‰¹é‡è½¬æ¢æˆæ¨¡å‹å¯ä»¥ç›´æ¥ä½¿ç”¨çš„æ ¼å¼ã€‚

> åœ¨ä½¿ç”¨ [convert_func.py](./ie2instruction/convert_func.py) è„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿å‚è€ƒäº† [data](./data) ç›®å½•ã€‚è¯¥ç›®å½•è¯¦ç»†è¯´æ˜äº†æ¯ç§ä»»åŠ¡æ‰€éœ€çš„æ•°æ®æ ¼å¼è¦æ±‚ã€‚ `sample.json` æè¿°äº†è½¬æ¢å‰æ•°æ®çš„æ ¼å¼ï¼Œ`schema.json` å±•ç¤ºäº† schema çš„ç»„ç»‡ç»“æ„ï¼Œ `train.json` æè¿°äº†è½¬æ¢åçš„æ•°æ®æ ¼å¼ã€‚

> æ­¤å¤–ï¼Œå¯ç›´æ¥ä½¿ç”¨åŒ…å«12ä¸ªä¸»é¢˜ï¼ˆå¦‚äººç‰©ã€äº¤é€šå·¥å…·ã€è‰ºæœ¯ä½œå“ã€è‡ªç„¶ç§‘å­¦ã€äººé€ ç‰©å“ã€å¤©æ–‡å¯¹è±¡ç­‰ï¼‰çš„ä¸­è‹±åŒè¯­ä¿¡æ¯æŠ½å–æ•°æ®é›† [zjunlp/InstructIE](https://huggingface.co/datasets/zjunlp/InstructIE)ã€‚

2. å…¶æ¬¡ï¼Œé€æ­¥æµ‹è¯•æ•°æ®é›†ã€‚åœ¨å‡†å¤‡æµ‹è¯•æ•°æ®è½¬æ¢ä¹‹å‰ï¼Œè¯·è®¿é—® [data](./data) ç›®å½•ä»¥äº†è§£å„ä»»åŠ¡æ‰€éœ€çš„æ•°æ®ç»“æ„ï¼š1ï¼‰è¾“å…¥æ•°æ®æ ¼å¼å‚è§ `sample.json`ï¼›2ï¼‰schemaæ ¼å¼è¯·æŸ¥çœ‹ `schema.json`ï¼›3ï¼‰è½¬æ¢åæ•°æ®æ ¼å¼å¯å‚ç…§ `train.json`ã€‚**ä¸è®­ç»ƒæ•°æ®ä¸åŒ, æµ‹è¯•æ•°æ®çš„è¾“å…¥æ— éœ€åŒ…å«æ ‡æ³¨å­—æ®µï¼ˆ`entity`, `relation`, `event`ï¼‰**ã€‚

ä½¿ç”¨è¿™ä¸ªå‘½ä»¤è¿›è¡Œæ•°æ®è½¬æ¢ï¼ˆéœ€è¦è‡ªå·±ä¿®æ”¹yamlå‚æ•°è°ƒæ•´æ˜¯**è®­ç»ƒæ•°æ®é›†**å’Œ**æµ‹è¯•æ•°æ®é›†**ï¼Œä»¥åŠå…¶ä»–å‚æ•°ï¼‰


```bash
python src/finetune.py
```

å¯ä»¥è‡ªå·±ä¿®æ”¹é…ç½®ï¼š[examples/fine_turning/convert.yaml]()

```bash
mode: train # åˆ‡ä¸ºtestå³ä¸ºæµ‹è¯•æ•°æ®é›†è½¬æ¢ï¼Œå…¶ä»–ä¸ç”¨æ”¹

train:
  src_path: data/NER/sample.json
  tgt_path: data/NER/train.json
  schema_path: data/NER/schema.json
  language: zh
  task: NER
  split_num: 6
  random_sort: true
  split: train

test:
  src_path: data/NER/sample.json
  tgt_path: data/NER/test.json
  schema_path: data/NER/schema.json
  language: zh
  task: NER
  split_num: 6
  split: test

hard_train:
  src_path: data/SPO/sample.json
  tgt_path: data/SPO/train.json
  schema_path: data/SPO/schema.json
  cluster_mode: true
  hard_negative_path: data/hard_negative/SPO_DuIE2.0.json
  language: zh
  task: SPO
  split_num: 4
  random_sort: true
  split: train

```

å‚æ•°è¯´æ˜ï¼š

* `mode` æ˜¯ç”¨æˆ·è‡ªå·±é€‰æ‹©ç”Ÿæˆè®­ç»ƒæ•°æ®è¿˜æ˜¯æµ‹è¯•æ•°æ®ã€‚

* `src_path` æ˜¯æ ·ä¾‹ï¼Œå³æè¿°äº†è½¬æ¢å‰æ•°æ®çš„æ ¼å¼ã€‚
* `tgt_path` æ˜¯è½¬æ¢åçš„æ•°æ®ã€‚**æµ‹è¯•ä¸è®­ç»ƒæ•°æ®ä¸åŒ, æµ‹è¯•æ•°æ®çš„è¾“å…¥æ— éœ€åŒ…å«æ ‡æ³¨å­—æ®µï¼ˆ`entity`, `relation`, `event`ï¼‰**ã€‚
* `language`: æ”¯æŒ`zh`, `en`ä¸¤ç§è¯­è¨€, ä¸åŒè¯­è¨€ä½¿ç”¨çš„æŒ‡ä»¤æ¨¡ç‰ˆä¸åŒã€‚
* `task`: ç›®å‰æ”¯æŒ['`RE`', '`NER`', '`EE`', '`EET`', '`EEA`', 'KG']ä»»åŠ¡ã€‚
* `split_num`: å®šä¹‰å•ä¸ªæŒ‡ä»¤ä¸­å¯åŒ…å«çš„æœ€å¤§schemaæ•°ç›®ã€‚é»˜è®¤å€¼ä¸º4ï¼Œè®¾ç½®ä¸º-1åˆ™ä¸è¿›è¡Œåˆ‡åˆ†ã€‚æ¨èçš„ä»»åŠ¡åˆ‡åˆ†æ•°é‡ä¾ä»»åŠ¡è€Œå¼‚ï¼š**NERå»ºè®®ä¸º6ï¼ŒREã€EEã€EETã€EEAå‡æ¨èä¸º4ã€KGæ¨èä¸º1**ã€‚
* `random_sort`: æ˜¯å¦å¯¹æŒ‡ä»¤ä¸­çš„schemaéšæœºæ’åº, é»˜è®¤ä¸ºFalse, å³æŒ‰å­—æ¯é¡ºåºæ’åºã€‚
* `split`(å¿…é€‰): æŒ‡å®šæ•°æ®é›†ç±»å‹ï¼Œ`train` (è®­ç»ƒé›†train.jsonã€éªŒè¯é›†dev.jsonå‡ä½¿ç”¨`train`) æˆ–`test`ã€‚è®¾ç½® `split` ä¸º **test** æ—¶ï¼Œè¯·æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©é€‚å½“çš„schemaæ•°é‡ï¼š**NERæ¨èä¸º6ï¼Œè€ŒREã€EEã€EETã€EEAæ¨èä¸º4**ã€‚

* è½¬æ¢åçš„è®­ç»ƒæ•°æ®å°†åŒ…å« `task`, `source`, `instruction`, `output` å››ä¸ªå­—æ®µã€‚

* è½¬æ¢åçš„æµ‹è¯•æ•°æ®å°†å«æœ‰`id`, `task`, `source`, `instruction`, `label`äº”ä¸ªå­—æ®µã€‚`label` å­—æ®µå°†ç”¨äºåç»­è¯„ä¼°ã€‚è‹¥è¾“å…¥æ•°æ®ä¸­ç¼ºå°‘æ ‡æ³¨å­—æ®µï¼ˆ`entity`, `relation`, `event`ï¼‰ï¼Œåˆ™è½¬æ¢åçš„æµ‹è¯•æ•°æ®å°†ä¸åŒ…å«`label`å­—æ®µï¼Œé€‚ç”¨äºé‚£äº›æ— åŸå§‹æ ‡æ³¨æ•°æ®çš„åœºæ™¯ã€‚



## ğŸš´ 3.å‡†å¤‡


### ğŸ› ï¸ 3.1ç¯å¢ƒ

åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ ¹æ®[DeepKE/example/llm/README_CN.md](../README_CN.md/#ç¯å¢ƒä¾èµ–)ä¸­çš„æŒ‡å¯¼åˆ›å»ºäº†é€‚å½“çš„Pythonè™šæ‹Ÿç¯å¢ƒã€‚åˆ›å»ºå¹¶é…ç½®å¥½**è™šæ‹Ÿç¯å¢ƒ**åï¼Œè¯·é€šè¿‡ä»¥ä¸‹å‘½ä»¤æ¿€æ´»åä¸º `deepke-llm` çš„ç¯å¢ƒï¼š

```bash
cd example/llm

conda create -n deepke-llm python=3.9
conda activate deepke-llm
pip install -r requirements.txt # æ³¨æ„ï¼ï¼æ˜¯example/llmæ–‡ä»¶å¤¹ä¸‹çš„ requirements.txt

!mkdir -p data         # è¯·æŠŠæ•°æ®æ”¾è¿™
!mkdir -p mdoels       # è¯·æŠŠåŸºç¡€æ¨¡å‹æ”¾è¿™
!mkdir -p results      # é¢„æµ‹ç»“æœ
!mkdir -p lora         # loraå¾®è°ƒç»“æœ
```


### ğŸ 3.2æ¨¡å‹

ä»¥ä¸‹æ˜¯æœ¬ä»“åº“ä»£ç æ”¯æŒçš„ä¸€äº›åŸºç¡€æ¨¡å‹ï¼š[[llama](https://huggingface.co/meta-llama), [alpaca](https://github.com/tloen/alpaca-lora), [vicuna](https://huggingface.co/lmsys), [zhixi](https://github.com/zjunlp/KnowLM), [falcon](https://huggingface.co/tiiuae), [baichuan](https://huggingface.co/baichuan-inc), [chatglm](https://huggingface.co/THUDM), [qwen](https://huggingface.co/Qwen), [moss](https://huggingface.co/fnlp), [openba](https://huggingface.co/OpenBA)]



## ğŸŒ° 4.LoRAå¾®è°ƒ

ä¸‹é¢æ˜¯ä¸€äº›å·²ç»ç»è¿‡å……åˆ†ä¿¡æ¯æŠ½å–æŒ‡ä»¤æ•°æ®è®­ç»ƒçš„æ¨¡å‹ï¼š

* [zjunlp/llama2-13b-iepile-lora](https://huggingface.co/zjunlp/llama2-13b-iepile-lora/tree/main) ï¼ˆåº•åº§æ¨¡å‹æ˜¯LLaMA2-13B-Chatï¼‰
* [zjunlp/baichuan2-13b-iepile-lora](https://huggingface.co/zjunlp/baichuan2-13b-iepile-lora) ï¼ˆåº•åº§æ¨¡å‹æ˜¯BaiChuan2-13B-Chatï¼‰
* [zjunlp/llama3-8b-iepile-lora](https://huggingface.co/zjunlp/llama3-8b-iepile-lora)
* [zjunlp/qwen1.5-14b-iepile-lora](https://huggingface.co/zjunlp/qwen1.5-14b-iepile-lora)
* [zjunlp/OneKE](https://huggingface.co/zjunlp/OneKE)


### 4.1åŸºç¡€å‚æ•°

> è¯·ç¡®ä¿æ‚¨çš„å½“å‰å·¥ä½œç›®å½•æ­£ç¡®ï¼Œä¸º`DeepKE/example/llm`
>
> é»˜è®¤å•æœºå¤šå¡è®­ç»ƒï¼Œåªéœ€å°†`example/llm/src/finetune.py`çš„è¡Œ121çš„"0,1,2,3"æ”¹ä¸ºå¯¹åº”çš„GPUç¼–å·å³å¯ä¸ºå•æœºå•å¡è®­ç»ƒã€‚

é¦–å…ˆéœ€è¦ç¡®å®šçš„æ˜¯å¤šå¡è¿˜æ˜¯å•å¡è®­ç»ƒï¼Œå»ºè®®å…ˆæ£€æŸ¥å½“å‰GPUæ•°é‡ï¼š

```bash
NUM_GPUS=$(nvidia-smi -L | wc -l)
```

å¦‚æœä½¿ç”¨å¤šå¡è®­ç»ƒï¼Œåˆ™ï¼š

```bash
CUDA_VISIBLE_DEVICES="0,1,2,3" torchrun --nproc_per_node=$NUM_GPUS --master_port=1287 src/finetune.py
```

å¦‚æœä½¿ç”¨å•å¡è®­ç»ƒï¼Œåˆ™ï¼š

```bash
CUDA_VISIBLE_DEVICES="0" python3 src/finetune.py
```

å…¶ä¸­ï¼Œé…ç½®å‚æ•°åœ¨`example/llm/examples/fine_turning/fine_llama.yaml`ä¸­ï¼Œå¯ä¾›è‡ªè¡Œä¿®æ”¹ï¼š

```bash
output_dir: 'lora/llama2-7b-chat-v1'
do_train: true
do_eval: true
overwrite_output_dir: true
stage: 'sft'
model_name_or_path: 'models/llama2-7b-chat'
model_name: 'llama'
template: 'llama2'
train_file: 'data/NER/train.json'
valid_file: 'data/dev.json'
val_set_size: 100
per_device_train_batch_size: 2
per_device_eval_batch_size: 2
gradient_accumulation_steps: 4
preprocessing_num_workers: 16
num_train_epochs: 10
learning_rate: 5e-5
max_grad_norm: 0.5
optim: "adamw_torch"
max_source_length: 400
cutoff_len: 700
max_target_length: 300
evaluation_strategy: "epoch"
save_strategy: "epoch"
save_total_limit: 10
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
bf16: true
bits: 4
```

å‚æ•°è¯´æ˜ï¼š

* `model_name`: æŒ‡å®šæ‰€éœ€çš„**æ¨¡å‹æ¶æ„åç§°**(7Bã€13Bã€Baseã€Chatå±äºåŒä¸€æ¨¡å‹æ¶æ„)ã€‚å½“å‰æ”¯æŒçš„æ¨¡å‹åŒ…æ‹¬ï¼š["`llama`", "`alpaca`", "`vicuna`", "`zhixi`", "`falcon`", "`baichuan`", "`chatglm`", "`qwen`", "`moss`", "`openba`"]ã€‚**è¯·æ³¨æ„**ï¼Œæ­¤å‚æ•°åº”ä¸ `--model_name_or_path` åŒºåˆ†ã€‚
* `model_name_or_path`: æ¨¡å‹è·¯å¾„, è¯·åˆ° [HuggingFace](https://huggingface.co/models) ä¸‹è½½ç›¸åº”æ¨¡å‹ã€‚
* `template`: ä½¿ç”¨çš„**æ¨¡æ¿åç§°**ï¼ŒåŒ…æ‹¬ï¼š`alpaca`, `baichuan`, `baichuan2`, `chatglm3`ç­‰, è¯·å‚è€ƒ [src/datamodule/template.py](./src/datamodule/template.py) æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„æ¨¡ç‰ˆåç§°, é»˜è®¤ä½¿ç”¨çš„æ˜¯`alpaca`æ¨¡æ¿, **`Chat`ç‰ˆæœ¬çš„æ¨¡å‹å»ºè®®ä½¿ç”¨é…å¥—çš„æ¨¡ç‰ˆ, Baseç‰ˆæœ¬æ¨¡å‹å¯é»˜è®¤ä½¿ç”¨`alpaca`**ã€‚
* `train_file`, `valid_fileï¼ˆå¯é€‰ï¼‰`: è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„**æ–‡ä»¶è·¯å¾„**ã€‚æ³¨æ„ï¼šç›®å‰ä»…æ”¯æŒjsonæ ¼å¼çš„æ–‡ä»¶ã€‚`valid_file`ä¸èƒ½æŒ‡å®šä¸º`test.json`æ–‡ä»¶(ä¸åŒ…å«outputå­—æ®µ,ä¼šæŠ¥é”™)ï¼Œå¯ä»¥é€šè¿‡æŒ‡å®š`val_set_size`å‚æ•°æ›¿ä»£`valid_file`ã€‚
* `output_dir`: LoRAå¾®è°ƒåçš„**æƒé‡å‚æ•°ä¿å­˜è·¯å¾„**ã€‚
* `val_set_size`: **éªŒè¯é›†çš„æ ·æœ¬æ•°é‡**, é»˜è®¤ä¸º1000ã€‚è‹¥æ²¡æœ‰æŒ‡å®š`valid_file`, å°†ä¼šä»`train_file`ä¸­åˆ’åˆ†å‡ºå¯¹åº”æ•°é‡çš„æ ·æœ¬ä½œä¸ºéªŒè¯é›†ã€‚
* `per_device_train_batch_size`, `per_device_eval_batch_size`: æ¯å°GPUè®¾å¤‡ä¸Šçš„`batch_size`, æ ¹æ®æ˜¾å­˜å¤§å°è°ƒæ•´, RTX3090å»ºè®®è®¾ç½®2~4ã€‚
* `max_source_length`, `max_target_length`, `cutoff_len`: æœ€å¤§è¾“å…¥ã€è¾“å‡ºé•¿åº¦ã€æˆªæ–­é•¿åº¦, æˆªæ–­é•¿åº¦å¯ä»¥ç®€å•åœ°è§†ä½œæœ€å¤§è¾“å…¥é•¿åº¦ + æœ€å¤§è¾“å‡ºé•¿åº¦, éœ€æ ¹æ®å…·ä½“éœ€æ±‚å’Œæ˜¾å­˜å¤§å°è®¾ç½®åˆé€‚å€¼ã€‚
* ä½¿ç”¨`deepspeed`, å¯è®¾ç½® `--deeepspeed configs/ds_config_bf16_stage2.json`

> å¯é€šè¿‡è®¾ç½® `bits` = 4 è¿›è¡Œé‡åŒ–, RTX3090å»ºè®®é‡åŒ–ã€‚

* è¦äº†è§£æ›´å¤šå…³äº**å‚æ•°é…ç½®**çš„ä¿¡æ¯ï¼Œè¯·å‚è€ƒ [src/utils/args](./src/args) ç›®å½•ã€‚

**å…¶ä½™æ–¹å¼ä¸¾ä¾‹ï¼š**


### 4.2LoRAå¾®è°ƒLLaMA

* `LLaMA3` é‡‡ç”¨çš„è„šæœ¬ä¹Ÿä¸€è‡´, ä»…éœ€**ä¿®æ”¹** `template` ä¸º`'alpaca'`

### 4.3LoRAå¾®è°ƒAlpaca

å¾®è°ƒAlpacaæ¨¡å‹æ—¶ï¼Œæ‚¨å¯éµå¾ªä¸[å¾®è°ƒLLaMAæ¨¡å‹](./README_CN.md/#42loraå¾®è°ƒllama)ç±»ä¼¼çš„æ­¥éª¤ã€‚è¦è¿›è¡Œå¾®è°ƒï¼Œè¯·**ä¿®æ”¹**ï¼š

```bash
output_dir: 'path to save Alpaca Lora'
model_name_or_path: 'path or name to Alpaca'
template: 'alpaca'
model_name: 'alpaca'
```

1. å¯¹äºtemplateï¼Œæˆ‘ä»¬**é»˜è®¤ä½¿ç”¨alpacaæ¨¡æ¿**ã€‚
2. `model_name = alpaca`


### 4.4LoRAå¾®è°ƒæ™ºæ

```bash
output_dir: 'path to save Zhixi Lora'
model_name_or_path: 'path or name to Zhixi'
model_name: 'zhixi'
template: 'alpaca'
```

1. ç”±äºZhixiç›®å‰åªæœ‰13bçš„æ¨¡å‹, å»ºè®®ç›¸åº”åœ°å‡å°æ‰¹å¤„ç†å¤§å°batch size
2. å¯¹äºtemplateï¼Œæˆ‘ä»¬**é»˜è®¤ä½¿ç”¨alpacaæ¨¡æ¿**ã€‚
3. `model_name = zhixi`


### 4.5LoRAå¾®è°ƒVicuna

ç›¸åº”çš„é…ç½®æ–‡ä»¶åœ¨ [examples/fine_turning/fine_vicuna.yaml]()

ä¿®æ”¹ä»¥ä¸‹é…ç½®ï¼š

```yaml
output_dir: 'lora/vicuna-7b-v1'  # æ”¹åŠ¨
model_name_or_path: 'models/vicuna-7b'  # æ”¹åŠ¨
model_name: 'vicuna'  # æ”¹åŠ¨
template: 'vicuna'  # æ”¹åŠ¨
```

1. ç”±äºVicuna-7b-delta-v1.1æ‰€ä½¿ç”¨çš„templateä¸`alpaca`**æ¨¡ç‰ˆä¸åŒ**, å› æ­¤éœ€è¦è®¾ç½® `template vicuna`ã€‚
2. `model_name = vicuna`

### 4.6LoRAå¾®è°ƒChatGLM

1. ChatGLMæ¨¡å‹æˆ‘ä»¬é‡‡ç”¨[THUDM/chatglm3-6b](https://huggingface.co/THUDM/chatglm3-6b)
2. `model_name = chatglm`
3. `template chatglm3`



### 4.7LoRAå¾®è°ƒMoss

1. Mossæ¨¡å‹æˆ‘ä»¬é‡‡ç”¨[moss-moon-003-sft](https://huggingface.co/fnlp/moss-moon-003-sft)
2. `model_name = moss`


### 4.8LoRAå¾®è°ƒBaichuan

1. Baichuanæ¨¡å‹æˆ‘ä»¬é‡‡ç”¨[baichuan-inc/Baichuan2-7B-Base](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base)
2. **è¯·ç¡®ä¿torchç‰ˆæœ¬ä¿æŒåœ¨2.0.0, å¦åˆ™å¯èƒ½å‡ºç°é—®é¢˜**
3. `model_name = baichuan`
4. `template baichuan2`
5. æˆ‘ä»¬å»ºè®®ä½¿ç”¨ `--bf16`
6. å¦‚æœå‡ºç°åœ¨evalåä¿å­˜æ—¶çˆ†æ˜¾å­˜è¯·è®¾ç½® `evaluation_strategy no`

### 4.9LoRAå¾®è°ƒQwen

1. **è¯·å°†accelerateç‰ˆæœ¬æ›´æ–°ä¸º0.27.2ï¼Œtransformersç‰ˆæœ¬æ›´æ–°ä¸º4.38.0, å¦åˆ™å¯èƒ½å‡ºç°é—®é¢˜**
2. `model_name = qwen2`
3. `template qwen`

* `Qwen1.5` é‡‡ç”¨çš„è„šæœ¬ä¹Ÿä¸€è‡´, ä»…éœ€ä¿®æ”¹ `model_name = qwen`

### 4.10é¢†åŸŸå†…æ•°æ®ç»§ç»­è®­ç»ƒ

å°½ç®¡ [zjunlp/llama2-13b-iepile-lora](https://huggingface.co/zjunlp/llama2-13b-iepile-lora/tree/main) | [zjunlp/baichuan2-13b-iepile-lora](https://huggingface.co/zjunlp/baichuan2-13b-iepile-lora) | [zjunlp/llama3-8b-iepile-lora](https://huggingface.co/zjunlp/llama3-8b-iepile-lora) | [zjunlp/qwen1.5-14b-iepile-lora](https://huggingface.co/zjunlp/qwen1.5-14b-iepile-lora) | [zjunlp/OneKE](https://huggingface.co/zjunlp/OneKE) ç­‰æ¨¡å‹å·²åœ¨å¤šä¸ªé€šç”¨æ•°æ®é›†ä¸Šæ¥å—äº†å¹¿æ³›çš„æŒ‡ä»¤å¾®è°ƒï¼Œå¹¶å› æ­¤è·å¾—äº†ä¸€å®šçš„**é€šç”¨ä¿¡æ¯æŠ½å–èƒ½åŠ›**ï¼Œä½†å®ƒä»¬åœ¨**ç‰¹å®šé¢†åŸŸ**ï¼ˆå¦‚`æ³•å¾‹`ã€`æ•™è‚²`ã€`ç§‘å­¦`ã€`ç”µä¿¡`ï¼‰çš„æ•°æ®å¤„ç†ä¸Šå¯èƒ½ä»æ˜¾ç¤ºå‡ºä¸€å®šçš„å±€é™æ€§ã€‚é’ˆå¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œå»ºè®®å¯¹è¿™äº›æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸçš„æ•°æ®é›†ä¸Šè¿›è¡Œ**äºŒæ¬¡è®­ç»ƒ**ã€‚è¿™å°†æœ‰åŠ©äºæ¨¡å‹æ›´å¥½åœ°é€‚åº”ç‰¹å®šé¢†åŸŸçš„è¯­ä¹‰å’Œç»“æ„ç‰¹å¾ï¼Œä»è€Œå¢å¼ºå…¶åœ¨**è¯¥é¢†åŸŸå†…çš„ä¿¡æ¯æŠ½å–èƒ½åŠ›**ã€‚


| checkpoint_dir            | model_name_or_path | moadel_name | fp16/bf16 | template  |
| ------------------------- | ------------------ | ----------- | --------- | --------- |
| llama2-13b-iepile-lora    | LLaMA2-13B-Chat    | llama       | bf16      | llama2    |
| baichuan2-13b-iepile-lora | BaiChuan2-13B-Chat | baichuan    | bf16      | baichuan2 |
| llama3-8b-iepile-lora     | LLaMA3-8B-Instruct | llama       | bf16      | alpaca    |
| qwen1.5-14b-iepile-lora   | Qwen1.5-14B-Chat   | qwen2       | bf16      | qwen      |
| OneKE                     | OneKE              | llama       | bf16      | llama2_zh |


#### Loraå¾®è°ƒ

```bash
output_dir: 'lora/oneke-continue'
do_train: true
do_eval: true
overwrite_output_dir: true
stage: 'sft'
model_name_or_path: 'models/OneKE'
model_name: 'llama'
template: 'llama2_zh'
train_file: 'data/train.json'
valid_file: 'data/dev.json'
val_set_size: 100
per_device_train_batch_size: 2
per_device_eval_batch_size: 2
gradient_accumulation_steps: 4
preprocessing_num_workers: 16
num_train_epochs: 10
learning_rate: 5e-5
max_grad_norm: 0.5
optim: "adamw_torch"
max_source_length: 400
cutoff_len: 700
max_target_length: 300
evaluation_strategy: "epoch"
save_strategy: "epoch"
save_total_limit: 10
lora_r: 64
lora_alpha: 64
lora_dropout: 0.05
bf16: true
bits: 4
```

* è‹¥è¦åŸºäºå¾®è°ƒåçš„LoRAæƒé‡ç»§ç»­è®­ç»ƒï¼Œä»…éœ€å°† `checkpoint_dir` å‚æ•°æŒ‡å‘LoRAæƒé‡è·¯å¾„ï¼Œä¾‹å¦‚è®¾ç½®ä¸º`'zjunlp/llama2-13b-iepile-lora'`ã€‚

* ä½¿ç”¨`deepspeed`, å¯è®¾ç½® `deeepspeed: "configs/ds_config_bf16_stage2.json"`

> å¯é€šè¿‡è®¾ç½® `bits` = 4 è¿›è¡Œé‡åŒ–, RTX3090å»ºè®®é‡åŒ–ã€‚

> è¯·æ³¨æ„ï¼Œåœ¨ä½¿ç”¨ `llama2-13b-iepile-lora`ã€`baichuan2-13b-iepile-lora` æ—¶ï¼Œä¿æŒlora_rå’Œlora_alphaå‡ä¸º64ï¼Œå¯¹äºè¿™äº›å‚æ•°ï¼Œæˆ‘ä»¬ä¸æä¾›æ¨èè®¾ç½®ã€‚

* è‹¥è¦åŸºäºå¾®è°ƒåçš„æ¨¡å‹æƒé‡ç»§ç»­è®­ç»ƒï¼Œåªéœ€è®¾å®š `model_name_or_path` å‚æ•°ä¸ºæƒé‡è·¯å¾„ï¼Œå¦‚`'zjunlp/OneKE'`ï¼Œæ— éœ€è®¾ç½®`checkpoint_dir`ã€‚


#### å…¨é‡å¾®è°ƒ

```bash
output_dir: 'lora/oneke-continue'
do_train: true
do_eval: true
overwrite_output_dir: true
stage: 'sft'
model_name_or_path: 'models/OneKE'
model_name: 'llama'
template: 'llama2_zh'
train_file: 'data/train.json'
valid_file: 'data/dev.json'
val_set_size: 100
per_device_train_batch_size: 2
per_device_eval_batch_size: 2
gradient_accumulation_steps: 4
preprocessing_num_workers: 16
num_train_epochs: 10
learning_rate: 5e-5
max_grad_norm: 0.5
optim: "adamw_torch"
max_source_length: 400
cutoff_len: 700
max_target_length: 300
evaluation_strategy: "epoch"
save_strategy: "epoch"
save_total_limit: 10
lora_dropout: 0.05
bf16: true
finetuning_type: 'full'
```


è„šæœ¬å¯ä»¥åœ¨ [examples/fine_turning/fine_continue.yaml]()ã€[examples/fine_turning/fine_continue_full.yaml]() ä¸­æ‰¾åˆ°ã€‚



## ğŸ¥Š 5.P-Tuningå¾®è°ƒ

### 5.1P-Tuningå¾®è°ƒChatGLM

ä½ å¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤ä½¿ç”¨P-Tuningæ–¹æ³•æ¥finetuneæ¨¡å‹:

```bash
deepspeed --include localhost:0 src/finetuning_chatglm_pt.py
```

é…ç½®ï¼ˆæ”¾åœ¨`examples/fine_turning/fine_pt_chatglm.yaml`ï¼‰ï¼š

```yaml
train_path: 'data/train.json'
model_dir: '/model'
num_train_epochs: 20
train_batch_size: 2
gradient_accumulation_steps: 1
output_dir: 'output_dir_pt'
log_steps: 10
max_len: 768
max_src_len: 450
pre_seq_len: 16
prefix_projection: true
```



## ğŸ”´ 6.é¢„æµ‹

### 6.1LoRAé¢„æµ‹

#### 6.1.1åŸºç¡€æ¨¡å‹+Lora

ä»¥ä¸‹æ˜¯ä¸€äº›ç»è¿‡LoRAæŠ€æœ¯è®­ç»ƒä¼˜åŒ–çš„æ¨¡å‹(**Loraæƒé‡**)ï¼š

<details>
  <summary><b>V1ç‰ˆæœ¬</b></summary>


* [alpaca-7b-lora-ie](https://huggingface.co/zjunlp/alpaca-7b-lora-ie)
* [llama-7b-lora-ie](https://huggingface.co/zjunlp/llama-7b-lora-ie)
* [alpaca-13b-lora-ie](https://huggingface.co/zjunlp/alpaca-13b-lora-ie)
* [knowlm-13b-ie-lora](https://huggingface.co/zjunlp/knowlm-13b-ie-lora)


| checkpoint_dir     | model_name_or_path          | moadel_name | fp16/bf16 | template |
| ------------------ | --------------------------- | ----------- | --------- | -------- |
| llama-7b-lora-ie   | llama-7b                    | llama       | fp16      | alpaca   |
| alpaca-7b-lora-ie  | alpaca-7b                   | alpaca      | fp16      | alpaca   |
| knowlm-13b-ie-lora | zjunlp/knowlm-13b-base-v1.0 | zhixi       | fp16      | alpaca   |

</details>

**V2ç‰ˆæœ¬(æ¨è)**

* [zjunlp/llama2-13b-iepile-lora](https://huggingface.co/zjunlp/llama2-13b-iepile-lora/tree/main)
* [zjunlp/baichuan2-13b-iepile-lora](https://huggingface.co/zjunlp/baichuan2-13b-iepile-lora)
* [zjunlp/llama3-8b-iepile-lora](https://huggingface.co/zjunlp/llama3-8b-iepile-lora)
* [zjunlp/qwen1.5-14b-iepile-lora](https://huggingface.co/zjunlp/qwen1.5-14b-iepile-lora)


| checkpoint_dir            | model_name_or_path | moadel_name | fp16/bf16 | template  |
| ------------------------- | ------------------ | ----------- | --------- | --------- |
| llama2-13b-iepile-lora    | LLaMA2-13B-Chat    | llama       | bf16      | llama2    |
| baichuan2-13b-iepile-lora | BaiChuan2-13B-Chat | baichuan    | bf16      | baichuan2 |
| llama3-8b-iepile-lora     | LLaMA3-8B-Instruct | llama       | bf16      | alpaca    |
| qwen1.5-14b-iepile-lora   | Qwen1.5-14B-Chat   | qwen2       | bf16      | qwen      |



è¦ä½¿ç”¨è¿™äº›**è®­ç»ƒå¥½çš„**LoRAæ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œå¯ä»¥æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
CUDA_VISIBLE_DEVICES=0 python src/inference.py
```

é…ç½®å¦‚ä¸‹ï¼š

```yaml
stage: sft
model_name_or_path: 'models/llama2-13B-Chat'
checkpoint_dir: 'lora/llama2-13b-IEPile-lora'
model_name: 'llama'
template: 'llama2'
# do_predict:
input_file: 'data/input.json'
output_file: 'results/llama2-13b-IEPile-lora_output.json'
finetuning_type: lora
output_dir: 'lora/test'
# predict_with_generate:
cutoff_len: 512
bf16: true
max_new_tokens: 300
bits: 4
```

* åœ¨è¿›è¡Œæ¨ç†æ—¶ï¼Œ`model_name`, `template`, å’Œ `bf16` å¿…é¡»ä¸è®­ç»ƒæ—¶çš„è®¾ç½®ç›¸åŒã€‚
* `model_name_or_path`: æŒ‡å®šæ‰€ä½¿ç”¨çš„åŸºç¡€æ¨¡å‹è·¯å¾„ï¼Œå¿…é¡»ä¸ç›¸åº”çš„LoRAæ¨¡å‹åŒ¹é…ã€‚
* `checkpoint_dir`: LoRAçš„æƒé‡æ–‡ä»¶è·¯å¾„ã€‚
* `output_dir`: æ­¤å‚æ•°åœ¨æ¨ç†æ—¶ä¸èµ·ä½œç”¨ï¼Œå¯ä»¥éšæ„æŒ‡å®šä¸€ä¸ªè·¯å¾„ã€‚
* `input_file`, `output_file`: åˆ†åˆ«æŒ‡å®šè¾“å…¥çš„æµ‹è¯•æ–‡ä»¶è·¯å¾„å’Œé¢„æµ‹ç»“æœçš„è¾“å‡ºæ–‡ä»¶è·¯å¾„ã€‚
* `cutoff_len`, `max_new_tokens`: è®¾ç½®æœ€å¤§çš„è¾“å…¥é•¿åº¦å’Œç”Ÿæˆçš„æ–°tokenæ•°é‡ï¼Œæ ¹æ®æ˜¾å­˜å¤§å°è¿›è¡Œè°ƒæ•´ã€‚

> å¯é€šè¿‡è®¾ç½® `bits` = 4 è¿›è¡Œé‡åŒ–, RTX3090å»ºè®®é‡åŒ–ã€‚

#### 6.1.2IEä¸“ç”¨æ¨¡å‹

| checkpoint_dir | model_name_or_path | moadel_name | fp16/bf16 | template  |
| -------------- | ------------------ | ----------- | --------- | --------- |
| OneKE          | OneKE              | llama       | bf16      | llama2_zh |


**`OneKE(based on chinese-alpaca2)`** æ¨¡å‹ä¸‹è½½é“¾æ¥ï¼š[zjunlp/OneKE](https://huggingface.co/zjunlp/OneKE)


è‹¥è¦ä½¿ç”¨**å·²è®­ç»ƒçš„æ¨¡å‹**ï¼ˆæ— LoRAæˆ–LoRAå·²é›†æˆåˆ°æ¨¡å‹å‚æ•°ä¸­ï¼‰ï¼Œå¯ä»¥æ”¹ä¸ºä»¥ä¸‹é…ç½®è¿›è¡Œé¢„æµ‹ï¼š

```yaml
stage: sft
model_name_or_path: 'models/OneKE'
model_name: 'llama'
template: 'llama2_zh'
# do_predict
input_file: 'data/input.json'
output_file: 'results/OneKE_output.json'
output_dir: 'lora/test'
# predict_with_generate
cutoff_len: 512
bf16: true
max_new_tokens: 300
bits: 4
```

`model_name_or_path`: IEä¸“ç”¨æ¨¡å‹æƒé‡è·¯å¾„

#### 6.1.3åˆå¹¶åŸºç¡€æ¨¡å‹+Loraå¯¼å‡º

```yaml
python src/export_model.py
```

å°†åº•åº§æ¨¡å‹å’Œè®­ç»ƒçš„Loraæƒé‡åˆå¹¶, å¯¼å‡ºæ¨¡å‹

```bash
model_name_or_path: 'models/Baichuan2-13B-Chat'
checkpoint_dir: 'lora_results/baichuan2-13b-v1/checkpoint-xxx'
export_dir: 'lora_results/baichuan2-13b-v1/baichuan2-13b-v1'
stage: 'sft'
model_name: 'baichuan'
template: 'baichuan2'
output_dir: 'lora_results/test'
```

æ³¨æ„ `template`ã€`model_name` ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ã€‚


#### 6.1.4vllmåŠ é€Ÿæ¨ç†

æ¨èç¯å¢ƒ:

```bash
pip install tiktoken
pip install peft==0.7.1
pip install transformers==4.41.2

pip install vllm==0.3.0
pip install jinja2==3.0.1
pip install pydantic==1.9.2

ip route add 8.8.8.8 via 127.0.0.1
```

è¿è¡Œè„šæœ¬

```yaml
python src/inference_vllm.py
```

å‚è€ƒé…ç½®`examples/fine_turning/vllm_baichuan.yaml`:

```yaml
stage: sft
model_name_or_path: 'lora_results/baichuan2-13b-v1/baichuan2-13b-v1'
model_name: 'baichuan'
template: 'baichuan2'
# do_predict:
input_file: 'data/input.json'
output_file: 'results/baichuan2-13b-IEPile-lora_output.json'
output_dir: 'lora_results/test'
batch_size: 4
# predict_with_generate:
max_source_length: 1024
bf16: true
max_new_tokens: 512
```




## ğŸ§¾ 7.è¯„ä¼°

æˆ‘ä»¬æä¾›äº†è¯„ä¼°å„ä¸ªä»»åŠ¡F1åˆ†æ•°çš„è„šæœ¬ã€‚

```bash
python ie2instruction/eval_func.py \
  --path1 results/llm_output.json \
  --task NER
```

* `path1` æ˜¯æ¨¡å‹çš„è¾“å‡ºæ–‡ä»¶, å…¶ä¸­ä¸€æ¡æ•°æ®æ ·æœ¬å¦‚ä¸‹æ‰€ç¤º, ç»æµ‹è¯•æ•°æ®è½¬æ¢è„šæœ¬è½¬æ¢åçš„æ•°æ®(`test.json`)å…·æœ‰`id`ã€`instruction`ã€`label`å­—æ®µ, `output`å­—æ®µæ˜¯ç»è¿‡æ¨¡å‹é¢„æµ‹è„šæœ¬åçš„æ¨¡å‹çœŸå®è¾“å‡ºã€‚

```json
{
  "id": "e88d2b42f8ca14af1b77474fcb18671ed3cacc0c75cf91f63375e966574bd187",
  "instruction": "{\"instruction\": \"ä½ æ˜¯ä¸“é—¨è¿›è¡Œå®ä½“æŠ½å–çš„ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„å®ä½“ï¼Œä¸å­˜åœ¨çš„å®ä½“ç±»å‹è¿”å›ç©ºåˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚\", \"schema\": [\"ç»„ç»‡æœºæ„\", \"åœ°ç†ä½ç½®\", \"äººç‰©\"], \"input\": \"ç›¸æ¯”ä¹‹ä¸‹ï¼Œé’å²›æµ·ç‰›é˜Ÿå’Œå¹¿å·æ¾æ—¥é˜Ÿçš„é›¨ä¸­ä¹‹æˆ˜è™½ç„¶ä¹Ÿæ˜¯0âˆ¶0ï¼Œä½†ä¹å–„å¯é™ˆã€‚\"}",
  "label": "[{\"entity\": \"å¹¿å·æ¾æ—¥é˜Ÿ\", \"entity_type\": \"ç»„ç»‡æœºæ„\"}, {\"entity\": \"é’å²›æµ·ç‰›é˜Ÿ\", \"entity_type\": \"ç»„ç»‡æœºæ„\"}]",
  "output": "{\"ç»„ç»‡æœºæ„\": [\"å¹¿å·æ¾æ—¥é˜Ÿ\", \"é’å²›æµ·ç‰›é˜Ÿ\"], \"äººç‰©\": [], \"åœ°ç†ä½ç½®\": []}"
}
```

* `task`: ç›®å‰æ”¯æŒ['RE', 'NER', 'EE', 'EET', 'EEA']äº”ç±»ä»»åŠ¡ã€‚
* å¯ä»¥è®¾ç½® `sort_by` ä¸º `source`, åˆ†åˆ«è®¡ç®—æ¯ä¸ªæ•°æ®é›†ä¸Šçš„F1åˆ†æ•°ã€‚





# ä¸Šä¸‹æ–‡å­¦ä¹ 

## ğŸ“— å•æ¬¡æ¨ç†

è¿è¡Œå‘½ä»¤ï¼š

```bash
python src/incontext_learning.py
```

é…ç½®ç¤ºä¾‹ï¼š

```bash
cwd: null
engine: "ChatGPT"
model_id: "gpt-3.5-turbo"
api_key: "Your API Key"
# base_url:
temperature: 0.3
top_p: 0.9
max_tokens: 100
stop: null
task: "re"
language: "en"
in_context: true
#instruction:
data_path: "data/ICL_Examples"
text_input: "Allen attended Lakeside School, where he met Gates, who was as obsessed with computer programming as he was."
domain: "Emotion Recognition"
labels: ["Emotion"]
head_entity: "Allen"
head_type: "People"
tail_entity: "Computer Programming"
tail_type: "Event"
```

æ›´å¤šè„šæœ¬æ ·ä¾‹è§äºï¼š `scripts/incontext_learning` ç›®å½•

è„šæœ¬å…¨å‚æ•°è¯´æ˜ï¼š

| å‚æ•°åç§°    | ç±»å‹  | æ„ä¹‰                                                         | é™å®š                                                         |
| ----------- | ----- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| engine      | str   | è¡¨ç¤ºæ‰€ç”¨çš„å¤§æ¨¡å‹åç§°ã€‚                                       | **å¿…é¡»**è¦æœ‰ï¼Œä¸”**å¿…é¡»**ä¸º `MODEL_LIST `ä¹‹ä¸€ã€‚               |
| api_key     | str   | ç”¨æˆ·çš„APIå¯†é’¥ã€‚                                              | è‹¥æ¨¡å‹ä¸ºé—­æºï¼Œåˆ™**å¿…é¡»**æä¾›ã€‚                               |
| base_url    | str   | åŸºç¡€ URLï¼Œç”¨äºæŒ‡å®š API è¯·æ±‚çš„åŸºç¡€åœ°å€ã€‚                      |                                                              |
| temperature | float | ç”¨äºæ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ã€‚                                   |                                                              |
| top_p       | float | æ ¸é‡‡æ ·ï¼ˆTop-pï¼‰å‚æ•°ï¼Œç”¨äºæ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§ã€‚              |                                                              |
| max_tokens  | int   | æœ€å¤§ token æ•°ï¼Œç”¨äºé™åˆ¶ç”Ÿæˆæ–‡æœ¬çš„é•¿åº¦ã€‚                      |                                                              |
| stop        | str   | åœæ­¢è¯ï¼Œç”¨äºæŒ‡å®šç”Ÿæˆæ–‡æœ¬æ—¶çš„ç»ˆæ­¢æ¡ä»¶ã€‚                       |                                                              |
| task        | str   | å‚æ•°ç”¨äºæŒ‡å®šä»»åŠ¡ç±»å‹ï¼Œå…¶ä¸­`ner`è¡¨ç¤ºå‘½åå®ä½“è¯†åˆ«ä»»åŠ¡ï¼Œ`re`è¡¨ç¤ºå…³ç³»æŠ½å–ä»»åŠ¡`ee`è¡¨ç¤ºäº‹ä»¶æŠ½å–ä»»åŠ¡ï¼Œ`rte`è¡¨ç¤ºä¸‰å…ƒç»„æŠ½å–ä»»åŠ¡ã€‚ | **å¿…é¡»**è¦æœ‰ï¼Œä¸”**å¿…é¡»**ä¸º `TASK_LIST` ä¹‹ä¸€ã€‚                |
| language    | str   | è¡¨ç¤ºä»»åŠ¡çš„è¯­è¨€ã€‚                                             | **å¿…é¡»**è¦æœ‰ï¼Œä¸”**å¿…é¡»**ä¸º `LANGUAGE_LIST` ä¹‹ä¸€ã€‚            |
| in_context  | bool  | æ˜¯å¦ä¸ºé›¶æ ·æœ¬è®¾å®šï¼Œä¸º`False`æ—¶è¡¨ç¤ºåªä½¿ç”¨instructionæç¤ºæ¨¡å‹è¿›è¡Œä¿¡æ¯æŠ½å–ï¼Œä¸º`True`æ—¶è¡¨ç¤ºä½¿ç”¨in-contextçš„å½¢å¼è¿›è¡Œä¿¡æ¯æŠ½å–ã€‚ |                                                              |
| instruction | str   | è§„å®šç”¨æˆ·è‡ªå®šä¹‰çš„æç¤ºæŒ‡ä»¤ï¼Œå½“ä¸ºç©ºæ—¶é‡‡ç”¨é»˜è®¤çš„æŒ‡ä»¤ã€‚           | ï¼ˆä¸å»ºè®®ä½¿ç”¨ï¼‰                                               |
| data_path   | str   | è¡¨ç¤ºin-context examplesçš„å­˜å‚¨ç›®å½•ï¼Œé»˜è®¤ä¸º`data`æ–‡ä»¶å¤¹ã€‚      |                                                              |
| text_input  | str   | åœ¨å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡(`ner`)ä¸­ï¼Œ`text_input`å‚æ•°ä¸ºé¢„æµ‹æ–‡æœ¬ï¼›åœ¨å…³ç³»æŠ½å–ä»»åŠ¡(`re`)ä¸­ï¼Œ`text_input`å‚æ•°ä¸ºæ–‡æœ¬ï¼›åœ¨äº‹ä»¶æŠ½å–ä»»åŠ¡(`ee`)ä¸­ï¼Œ`text_input`å‚æ•°ä¸ºå¾…é¢„æµ‹æ–‡æœ¬ï¼›åœ¨ä¸‰å…ƒç»„æŠ½å–ä»»åŠ¡(`rte`)ä¸­ï¼Œ`text_input`å‚æ•°ä¸ºå¾…é¢„æµ‹æ–‡æœ¬ã€‚ | æ‰€æœ‰ä»»åŠ¡**å¿…é¡»**è¦æœ‰ã€‚                                       |
| domain      | str   | åœ¨å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡(`ner`)ä¸­ï¼Œ`domain`ä¸ºé¢„æµ‹æ–‡æœ¬æ‰€å±é¢†åŸŸï¼Œå¯ä¸ºç©ºï¼›åœ¨å…³ç³»æŠ½å–ä»»åŠ¡(`re`)ä¸­ï¼Œ`domain`ä¸ºæ–‡æœ¬æ‰€å±é¢†åŸŸï¼Œå¯ä¸ºç©ºï¼›åœ¨äº‹ä»¶æŠ½å–ä»»åŠ¡(`ee`)ä¸­ï¼Œ`domain`ä¸ºé¢„æµ‹æ–‡æœ¬æ‰€å±é¢†åŸŸï¼Œå¯ä¸ºç©ºï¼›åœ¨ä¸‰å…ƒç»„æŠ½å–ä»»åŠ¡(`rte`)ä¸­ï¼Œ`domain`ä¸ºé¢„æµ‹æ–‡æœ¬æ‰€å±é¢†åŸŸï¼Œå¯ä¸ºç©ºã€‚ | ä»»åŠ¡ä¸º nerã€reã€eeã€rte ä¹‹ä¸€æ—¶ï¼Œå»ºè®®è®¾ç½®ã€‚                   |
| labels      | str   | åœ¨å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡(`ner`)ä¸­ï¼Œ`labels`ä¸ºå®ä½“æ ‡ç­¾é›†ï¼Œå¦‚æ— è‡ªå®šä¹‰çš„æ ‡ç­¾é›†ï¼Œè¯¥å‚æ•°å¯ä¸ºç©ºï¼›åœ¨å…³ç³»æŠ½å–ä»»åŠ¡(`re`)ä¸­ï¼Œ`labels`ä¸ºå…³ç³»ç±»å‹æ ‡ç­¾é›†ï¼Œå¦‚æ— è‡ªå®šä¹‰çš„æ ‡ç­¾é›†ï¼Œè¯¥å‚æ•°å¯ä¸ºç©ºã€‚`da`ä¸­`lables`ä¸ºå¤´å°¾å®ä½“è¢«é¢„å…ˆåˆ†ç±»çš„ç±»å‹ã€‚ | ä»»åŠ¡ä¸º da æ—¶ï¼Œ**å¿…é¡»**è¦æœ‰ã€‚ä»»åŠ¡ä¸º nerã€re ä¹‹ä¸€æ—¶ï¼Œå»ºè®®è®¾ç½®ã€‚å¤šä¸ªæ ‡ç­¾æ—¶ï¼Œç”¨é€—å·åˆ†å‰²ã€‚ |
| head_entity | str   | å¾…é¢„æµ‹å…³ç³»çš„å¤´å®ä½“å’Œå°¾å®ä½“ã€‚                                 | ä»»åŠ¡ä¸º re æ—¶ï¼Œ**å¿…é¡»**è¦æœ‰ã€‚                                 |
| tail_entity | str   | å¾…é¢„æµ‹å…³ç³»çš„å¤´å®ä½“å’Œå°¾å®ä½“ã€‚                                 | ä»»åŠ¡ä¸º re æ—¶ï¼Œ**å¿…é¡»**è¦æœ‰ã€‚                                 |
| head_type   | str   | å¾…é¢„æµ‹å…³ç³»çš„å¤´å°¾å®ä½“ç±»å‹ã€‚                                   | ä»»åŠ¡ä¸º re æ—¶ï¼Œ**å¿…é¡»**è¦æœ‰ã€‚                                 |
| tail_type   | str   | å¾…é¢„æµ‹å…³ç³»çš„å¤´å°¾å®ä½“ç±»å‹ã€‚                                   | ä»»åŠ¡ä¸º re æ—¶ï¼Œ**å¿…é¡»**è¦æœ‰ã€‚                                 |

## ğŸ“š æ‰¹é‡æ¨ç†

æ•°æ®é›†æ”¯æŒï¼š

| åç§°       | ä¸‹è½½                                                         | æ•°é‡  | æè¿°                                                         |
| ---------- | ------------------------------------------------------------ | ----- | ------------------------------------------------------------ |
| InstructIE | [Google drive](https://drive.google.com/file/d/1raf0h98x3GgIhaDyNn1dLle9_HvwD6wT/view?usp=sharing) [Hugging Face](https://huggingface.co/datasets/zjunlp/InstructIE) [ModelScope](https://modelscope.cn/datasets/ZJUNLP/InstructIE) [WiseModel](https://wisemodel.cn/datasets/zjunlp/InstructIE) | 30w+  | **åŒè¯­**(ä¸­æ–‡å’Œè‹±æ–‡)åŸºäºä¸»é¢˜çš„ä¿¡æ¯æŠ½å–(IE)æŒ‡ä»¤æ•°æ®é›†         |
| IEPile     | [Google Drive](https://drive.google.com/file/d/1jPdvXOTTxlAmHkn5XkeaaCFXQkYJk5Ng/view?usp=sharing) [Hugging Face](https://huggingface.co/datasets/zjunlp/iepile) [WiseModel](https://wisemodel.cn/datasets/zjunlp/IEPile) [ModelScpoe](https://modelscope.cn/datasets/ZJUNLP/IEPile) | 200w+ | å¤§è§„æ¨¡(`0.32B` tokens)é«˜è´¨é‡**åŒè¯­**(ä¸­æ–‡å’Œè‹±æ–‡)ä¿¡æ¯æŠ½å–(IE)æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† |

æ•°æ®å‡†å¤‡åŒæ ·å‚è€ƒå¾®è°ƒéƒ¨åˆ†çš„æ•°æ®è½¬æ¢ã€‚

è¿è¡Œè„šæœ¬ï¼š

```bash
python src/incontext_learning_plus.py
```
