# InstructionKGC-æŒ‡ä»¤é©±åŠ¨çš„è‡ªé€‚åº”çŸ¥è¯†å›¾è°±æ„å»º

<p align="left">
    <b> <a href="https://github.com/zjunlp/DeepKE/tree/main/example/llm/InstructKGC/README.md">English</a> | ç®€ä½“ä¸­æ–‡ </b>
</p>


- [InstructionKGC-æŒ‡ä»¤é©±åŠ¨çš„è‡ªé€‚åº”çŸ¥è¯†å›¾è°±æ„å»º](#instructionkgc-æŒ‡ä»¤é©±åŠ¨çš„è‡ªé€‚åº”çŸ¥è¯†å›¾è°±æ„å»º)
  - [æ–°é—»](#æ–°é—»)
  - [ğŸ¯ 1.ä»»åŠ¡ç›®æ ‡](#-1ä»»åŠ¡ç›®æ ‡)
  - [ğŸ“Š 2.æ•°æ®](#-2æ•°æ®)
    - [2.1ç°æœ‰æ•°æ®é›†](#21ç°æœ‰æ•°æ®é›†)
    - [2.2è®­ç»ƒæ•°æ®è½¬æ¢](#22è®­ç»ƒæ•°æ®è½¬æ¢)
    - [2.3æµ‹è¯•æ•°æ®è½¬æ¢](#23æµ‹è¯•æ•°æ®è½¬æ¢)
  - [ğŸš´ 3.å‡†å¤‡](#-3å‡†å¤‡)
    - [ğŸ› ï¸ 3.1ç¯å¢ƒ](#ï¸-31ç¯å¢ƒ)
    - [ğŸ 3.2æ¨¡å‹](#-32æ¨¡å‹)
  - [ğŸŒ° 4.LoRAå¾®è°ƒ](#-4loraå¾®è°ƒ)
    - [4.1åŸºç¡€å‚æ•°](#41åŸºç¡€å‚æ•°)
    - [4.2LoRAå¾®è°ƒLLaMA](#42loraå¾®è°ƒllama)
    - [4.3LoRAå¾®è°ƒAlpaca](#43loraå¾®è°ƒalpaca)
    - [4.4LoRAå¾®è°ƒæ™ºæ](#44loraå¾®è°ƒæ™ºæ)
    - [4.5LoRAå¾®è°ƒVicuna](#45loraå¾®è°ƒvicuna)
    - [4.6LoRAå¾®è°ƒChatGLM](#46loraå¾®è°ƒchatglm)
    - [4.7LoRAå¾®è°ƒMoss](#47loraå¾®è°ƒmoss)
    - [4.8LoRAå¾®è°ƒBaichuan](#48loraå¾®è°ƒbaichuan)
    - [4.9é¢†åŸŸå†…æ•°æ®ç»§ç»­è®­ç»ƒ](#49é¢†åŸŸå†…æ•°æ®ç»§ç»­è®­ç»ƒ)
  - [ğŸ¥Š 5.P-Tuningå¾®è°ƒ](#-5p-tuningå¾®è°ƒ)
    - [5.1P-Tuningå¾®è°ƒChatGLM](#51p-tuningå¾®è°ƒchatglm)
  - [ğŸ”´ 6.é¢„æµ‹](#-6é¢„æµ‹)
    - [6.1LoRAé¢„æµ‹](#61loraé¢„æµ‹)
      - [6.1.1åŸºç¡€æ¨¡å‹+Lora](#611åŸºç¡€æ¨¡å‹lora)
      - [6.1.2IEä¸“ç”¨æ¨¡å‹](#612ieä¸“ç”¨æ¨¡å‹)
    - [6.2P-Tuningé¢„æµ‹](#62p-tuningé¢„æµ‹)
  - [ğŸ§¾ 7.è¯„ä¼°](#-7è¯„ä¼°)
  - [ğŸ‘‹ 8.Acknowledgment](#-8acknowledgment)
  - [9.å¼•ç”¨](#9å¼•ç”¨)


## æ–°é—»
* [2024/02] æˆ‘ä»¬å‘å¸ƒäº†ä¸€ä¸ªå¤§è§„æ¨¡(`0.32B` tokens)é«˜è´¨é‡**åŒè¯­**(ä¸­æ–‡å’Œè‹±æ–‡)ä¿¡æ¯æŠ½å–(IE)æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œåä¸º [IEPile](https://huggingface.co/datasets/zjunlp/iepie), ä»¥åŠåŸºäº `IEPile` è®­ç»ƒçš„ä¸¤ä¸ªæ¨¡å‹[baichuan2-13b-iepile-lora](https://huggingface.co/zjunlp/baichuan2-13b-iepile-lora)ã€[llama2-13b-iepile-lora](https://huggingface.co/zjunlp/llama2-13b-iepile-lora)ã€‚
* [2023/10] æˆ‘ä»¬å‘å¸ƒäº†ä¸€ä¸ªæ–°çš„**åŒè¯­**(ä¸­æ–‡å’Œè‹±æ–‡)åŸºäºä¸»é¢˜çš„ä¿¡æ¯æŠ½å–(IE)æŒ‡ä»¤æ•°æ®é›†ï¼Œåä¸º[InstructIE](https://huggingface.co/datasets/zjunlp/InstructIE)å’Œ[è®ºæ–‡](https://arxiv.org/abs/2305.11527)ã€‚
* [2023/08] æˆ‘ä»¬æ¨å‡ºäº†ä¸“ç”¨äºä¿¡æ¯æŠ½å–(IE)çš„13Bæ¨¡å‹ï¼Œåä¸º[knowlm-13b-ie](https://huggingface.co/zjunlp/knowlm-13b-ie/tree/main)ã€‚
* [2023/05] æˆ‘ä»¬å¯åŠ¨äº†åŸºäºæŒ‡ä»¤çš„ä¿¡æ¯æŠ½å–é¡¹ç›®ã€‚



## ğŸ¯ 1.ä»»åŠ¡ç›®æ ‡

æˆ‘ä»¬å°†`Instruction-based KGC`åˆ¶å®šä¸ºä¸€ç§éµå¾ªæŒ‡ä»¤çš„è‡ªå›å½’ç”Ÿæˆä»»åŠ¡ã€‚æ¨¡å‹é¦–å…ˆéœ€è¦ç†è§£æŒ‡ä»¤è¯†åˆ«å…¶æ„å›¾ï¼Œç„¶åæ ¹æ®æŒ‡ä»¤å†…å®¹ï¼Œæ¨¡å‹ä¼šåŸºäºè¾“å…¥çš„æ–‡æœ¬æŠ½å–ç›¸åº”çš„ä¸‰å…ƒç»„å¹¶ä»¥æŒ‡å®šçš„æ ¼å¼è¾“å‡ºã€‚æœ¬æ–‡çš„ **`instruction`** æ ¼å¼é‡‡çº³äº†ç±»JSONå­—ç¬¦ä¸²çš„ç»“æ„ï¼Œå®è´¨ä¸Šæ˜¯ä¸€ç§å­—å…¸å‹å­—ç¬¦ä¸²ã€‚å®ƒç”±ä»¥ä¸‹ä¸‰ä¸ªå­—æ®µæ„æˆï¼š
(1) **`'instruction'`**ï¼Œå³ä»»åŠ¡æè¿°ï¼Œä»¥è‡ªç„¶è¯­è¨€æŒ‡å®šæ¨¡å‹æ‰®æ¼”çš„è§’è‰²ä»¥åŠéœ€è¦å®Œæˆçš„ä»»åŠ¡ï¼›
(2) **`'schema'`**ï¼Œè¿™æ˜¯ä¸€ä»½éœ€æå–çš„æ ‡ç­¾åˆ—è¡¨ï¼Œæ˜ç¡®æŒ‡å‡ºäº†å¾…æŠ½å–ä¿¡æ¯çš„å…³é”®å­—æ®µï¼Œååº”ç”¨æˆ·çš„éœ€æ±‚ï¼Œæ˜¯åŠ¨æ€å¯å˜çš„ï¼›
(3) **`'input'`**ï¼ŒæŒ‡çš„æ˜¯ç”¨äºä¿¡æ¯æŠ½å–çš„æºæ–‡æœ¬ã€‚å„ç±»ä»»åŠ¡å¯¹åº”çš„æŒ‡ä»¤æ ·ä¾‹ã€‚


ä»¥ä¸‹æ˜¯ä¸€æ¡**æ•°æ®å®ä¾‹**ï¼š

```json
{
  "instruction": "{\"instruction\": \"ä½ æ˜¯ä¸“é—¨è¿›è¡Œå®ä½“æŠ½å–çš„ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„å®ä½“ï¼Œä¸å­˜åœ¨çš„å®ä½“ç±»å‹è¿”å›ç©ºåˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚\", \"schema\": [\"ç»„ç»‡æœºæ„\", \"åœ°ç†ä½ç½®\", \"äººç‰©\"], \"input\": \"å¯¹äºåº·æœ‰ä¸ºã€æ¢å¯è¶…ã€è°­å—£åŒã€ä¸¥å¤è¿™äº›ä»æ—§æ–‡åŒ–è¥å’ä¸­èµ°æ¥çš„å¹´è½»â€œå¸ƒè¡£â€ï¼Œä»–ä»¬èƒŒè´Ÿç€æ²‰é‡çš„å†å²åŒ…è¢±ï¼Œèƒ½å¤ŸæŒ£è„±æ—§ä¼ ç»Ÿçš„æŸç¼šï¼Œä¸ºæ‹¯æ•‘æ°‘æ—çš„å±äº¡è€ŒçŒ®èº«ï¼Œå®åœ¨æ˜¯ä¸­åæ°‘æ—çš„è„Šæ¢ã€‚\"}", 
  "output": "{\"ç»„ç»‡æœºæ„\": [], \"åœ°ç†ä½ç½®\": [\"ä¸­å\"], \"äººç‰©\": [\"åº·æœ‰ä¸º\", \"æ¢å¯è¶…\", \"è°­å—£åŒ\", \"ä¸¥å¤\"]}"
}
```

å¾…æŠ½å–çš„schemaåˆ—è¡¨æ˜¯ ["ç»„ç»‡æœºæ„", "åœ°ç†ä½ç½®", "äººç‰©"], å¾…æŠ½å–çš„æ–‡æœ¬æ˜¯"*å¯¹äºåº·æœ‰ä¸ºã€æ¢å¯è¶…ã€è°­å—£åŒã€ä¸¥å¤è¿™äº›ä»æ—§æ–‡åŒ–è¥å’ä¸­èµ°æ¥çš„å¹´è½»â€œå¸ƒè¡£â€ï¼Œä»–ä»¬èƒŒè´Ÿç€æ²‰é‡çš„å†å²åŒ…è¢±ï¼Œèƒ½å¤ŸæŒ£è„±æ—§ä¼ ç»Ÿçš„æŸç¼šï¼Œä¸ºæ‹¯æ•‘æ°‘æ—çš„å±äº¡è€ŒçŒ®èº«ï¼Œå®åœ¨æ˜¯ä¸­åæ°‘æ—çš„è„Šæ¢ã€‚*", è¾“å‡ºæ˜¯ `{"ç»„ç»‡æœºæ„": [], "åœ°ç†ä½ç½®": ["ä¸­å"], "äººç‰©": ["åº·æœ‰ä¸º", "æ¢å¯è¶…", "è°­å—£åŒ", "ä¸¥å¤"]}`

> æ³¨æ„è¾“å‡ºä¸­çš„ schema é¡ºåºä¸ instruction ä¸­çš„ schema é¡ºåºä¸€è‡´


<details>
  <summary><b>æ›´å¤šä»»åŠ¡çš„æ•°æ®å®ä¾‹</b></summary>

```json
{
  "instruction": "{\"instruction\": \"ä½ æ˜¯ä¸“é—¨è¿›è¡Œå…³ç³»æŠ½å–çš„ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„å…³ç³»ä¸‰å…ƒç»„ï¼Œä¸å­˜åœ¨çš„å…³ç³»è¿”å›ç©ºåˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚\", \"schema\": [\"å›½ç±\", \"ä½œè€…\", \"æ¯•ä¸šé™¢æ ¡\", \"ä¸»è§’\"], \"input\": \"å¯¹æ¯”æ—¥æœ¬åŠ¨ç”»ç”µå½±åœ¨ä¸­æ—¥ä¸¤å›½çš„ç¥¨æˆ¿è¡¨ç°ï¼Œå¯ä»¥å‘ç°ï¼Œæ—¥æ¼«é£æ ¼çš„åŠ¨ç”»ï¼Œåœ¨å›½å†…ä¹Ÿæœ‰åœˆå±‚é™åˆ¶ï¼Œå³ä¾¿æ˜¯å®«å´éªã€Šåƒä¸åƒå¯»ã€‹ã€æ–°æµ·è¯šã€Šä½ çš„åå­—ã€‹ï¼Œè¿™ç±»æ—¥æœ¬åŠ¨ç”»ç¥¨æˆ¿æ¦œé¦–çš„ç”µå½±ï¼Œå›½å†…ç¥¨æˆ¿ä¹Ÿåœç•™åœ¨5äº¿å·¦å³\"}", 
  "output": "{\"å›½ç±\": [], \"ä½œè€…\": [{\"subject\": \"ä½ çš„åå­—\", \"object\": \"æ–°æµ·è¯š\"}], \"æ¯•ä¸šé™¢æ ¡\": [], \"ä¸»è§’\": []}"
}

{
  "instruction": "{\"instruction\": \"ä½ æ˜¯ä¸“é—¨è¿›è¡Œäº‹ä»¶æå–çš„ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„äº‹ä»¶ï¼Œä¸å­˜åœ¨çš„äº‹ä»¶è¿”å›ç©ºåˆ—è¡¨ï¼Œä¸å­˜åœ¨çš„è®ºå…ƒè¿”å›NANï¼Œå¦‚æœè®ºå…ƒå­˜åœ¨å¤šå€¼è¯·è¿”å›åˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚\", \"schema\": [{\"event_type\": \"äººç”Ÿ-æ±‚å©š\", \"trigger\": true, \"arguments\": [\"æ±‚å©šå¯¹è±¡\"]}, {\"event_type\": \"äººç”Ÿ-è®¢å©š\", \"trigger\": true, \"arguments\": [\"è®¢å©šä¸»ä½“\", \"æ—¶é—´\"]}, {\"event_type\": \"ç¾å®³/æ„å¤–-å/å®å¡Œ\", \"trigger\": true, \"arguments\": [\"å—ä¼¤äººæ•°\", \"åå¡Œä¸»ä½“\"]}, {\"event_type\": \"äººç”Ÿ-å¤±è”\", \"trigger\": true, \"arguments\": [\"åœ°ç‚¹\", \"å¤±è”è€…\"]}], \"input\": \"éƒ­ç¢§å©·è®¢å©šåï¼Œå¡«èµ„æ–™ä¾æ—§æƒ³è¦å¡«å•èº«ï¼Œæœ‰è°æ³¨æ„å‘ä½è¯´äº†ä»€ä¹ˆï¼Ÿ\"}", 
  "output": "{\"äººç”Ÿ-æ±‚å©š\": [], \"äººç”Ÿ-è®¢å©š\": [{\"trigger\": \"è®¢å©š\", \"arguments\": {\"è®¢å©šä¸»ä½“\": [\"å‘ä½\", \"éƒ­ç¢§å©·\"], \"æ—¶é—´\": \"NAN\"}}], \"ç¾å®³/æ„å¤–-å/å®å¡Œ\": [], \"äººç”Ÿ-å¤±è”\": []}"
}
```

</details>


[instruction.py](./ie2instruction/convert/utils/instruction.py) ä¸­æä¾›äº†å„ä¸ªä»»åŠ¡çš„æŒ‡ä»¤æ¨¡ç‰ˆã€‚



> **æ³¨æ„**âš ï¸: è€ç‰ˆçš„æ•°æ®æ ·å¼è¯·å‚è€ƒ[kg2instruction/README.md](./kg2instruction/README.md)



## ğŸ“Š 2.æ•°æ®


### 2.1ç°æœ‰æ•°æ®é›†

| åç§° | ä¸‹è½½ | æ•°é‡ | æè¿° |
| --- | --- | --- | --- |
| InstructIE | [Google drive](https://drive.google.com/file/d/1raf0h98x3GgIhaDyNn1dLle9_HvwD6wT/view?usp=sharing) <br/> [Hugging Face](https://huggingface.co/datasets/zjunlp/InstructIE) <br/> [ModelScope](https://modelscope.cn/datasets/ZJUNLP/InstructIE)<br/> [WiseModel](https://wisemodel.cn/datasets/zjunlp/InstructIE) | 30w+ | **åŒè¯­**(ä¸­æ–‡å’Œè‹±æ–‡)åŸºäºä¸»é¢˜çš„ä¿¡æ¯æŠ½å–(IE)æŒ‡ä»¤æ•°æ®é›† |
| IEPile | [Google Drive](https://drive.google.com/file/d/1jPdvXOTTxlAmHkn5XkeaaCFXQkYJk5Ng/view?usp=sharing) <br/> [Hugging Face](https://huggingface.co/datasets/zjunlp/iepile) <br/> [WiseModel](https://wisemodel.cn/datasets/zjunlp/IEPile) <br/> [ModelScpoe](https://modelscope.cn/datasets/ZJUNLP/IEPile) | 200w+ | å¤§è§„æ¨¡(`0.32B` tokens)é«˜è´¨é‡**åŒè¯­**(ä¸­æ–‡å’Œè‹±æ–‡)ä¿¡æ¯æŠ½å–(IE)æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† |


<details>
  <summary><b>InstructIEè¯¦ç»†ä¿¡æ¯</b></summary>

**ä¸€æ¡æ•°æ®çš„ç¤ºä¾‹**

```json
{
  "id": "bac7c32c47fddd20966e4ece5111690c9ce3f4f798c7c9dfff7721f67d0c54a5", 
  "cate": "åœ°ç†åœ°åŒº", 
  "text": "é˜¿å°”å¤«è¾¾å°”ï¼ˆæŒªå¨è¯­ï¼šAlvdalï¼‰æ˜¯æŒªå¨çš„ä¸€ä¸ªå¸‚é•‡ï¼Œä½äºå†…é™†éƒ¡ï¼Œè¡Œæ”¿ä¸­å¿ƒä¸ºé˜¿å°”å¤«è¾¾å°”æ‘ã€‚å¸‚é•‡é¢ç§¯ä¸º943å¹³æ–¹å…¬é‡Œï¼Œäººå£æ•°é‡ä¸º2,424äººï¼ˆ2018å¹´ï¼‰ï¼Œäººå£å¯†åº¦ä¸ºæ¯å¹³æ–¹å…¬é‡Œ2.6äººã€‚", 
  "relation": [
    {"head": "é˜¿å°”å¤«è¾¾å°”", "head_type": "åœ°ç†åœ°åŒº", "relation": "é¢ç§¯", "tail": "943å¹³æ–¹å…¬é‡Œ", "tail_type": "åº¦é‡"}, 
    {"head": "é˜¿å°”å¤«è¾¾å°”", "head_type": "åœ°ç†åœ°åŒº", "relation": "åˆ«å", "tail": "Alvdal", "tail_type": "åœ°ç†åœ°åŒº"}, 
    {"head": "å†…é™†éƒ¡", "head_type": "åœ°ç†åœ°åŒº", "relation": "ä½äº", "tail": "æŒªå¨", "tail_type": "åœ°ç†åœ°åŒº"}, 
    {"head": "é˜¿å°”å¤«è¾¾å°”", "head_type": "åœ°ç†åœ°åŒº", "relation": "ä½äº", "tail": "å†…é™†éƒ¡", "tail_type": "åœ°ç†åœ°åŒº"}, 
    {"head": "é˜¿å°”å¤«è¾¾å°”", "head_type": "åœ°ç†åœ°åŒº", "relation": "äººå£", "tail": "2,424äºº", "tail_type": "åº¦é‡"}
  ]
}
```

å„å­—æ®µçš„è¯´æ˜:

|    å­—æ®µ      |                             è¯´æ˜                             |
| :---------: | :----------------------------------------------------------: |
|     id      |                       æ¯ä¸ªæ•°æ®ç‚¹çš„å”¯ä¸€æ ‡è¯†ç¬¦ã€‚                       |
|    cate     |           æ–‡æœ¬çš„ä¸»é¢˜ç±»åˆ«ï¼Œæ€»è®¡12ç§ä¸åŒçš„ä¸»é¢˜åˆ†ç±»ã€‚               |
|    text     | æ¨¡å‹çš„è¾“å…¥æ–‡æœ¬ï¼Œç›®æ ‡æ˜¯ä»ä¸­æŠ½å–æ¶‰åŠçš„æ‰€æœ‰å…³ç³»ä¸‰å…ƒç»„ã€‚                  |
|  relation   |   æè¿°æ–‡æœ¬ä¸­åŒ…å«çš„å…³ç³»ä¸‰å…ƒç»„ï¼Œå³(head, head_type, relation, tail, tail_type)ã€‚   |

éœ€è¦å‚è€ƒæ•°æ®è½¬æ¢

</details>


<details>
  <summary><b>IEPileè¯¦ç»†ä¿¡æ¯</b></summary>


`IEPile` ä¸­çš„æ¯æ¡æ•°æ®å‡åŒ…å« `task`, `source`, `instruction`, `output` 4ä¸ªå­—æ®µ, ä»¥ä¸‹æ˜¯å„å­—æ®µçš„è¯´æ˜

| å­—æ®µ | è¯´æ˜ |
| :---: | :---: |
| task | è¯¥å®ä¾‹æ‰€å±çš„ä»»åŠ¡, (`NER`ã€`RE`ã€`EE`ã€`EET`ã€`EEA`) 5ç§ä»»åŠ¡ä¹‹ä¸€ã€‚ |
| source | è¯¥å®ä¾‹æ‰€å±çš„æ•°æ®é›† |
| instruction | è¾“å…¥æ¨¡å‹çš„æŒ‡ä»¤, ç»è¿‡json.dumpså¤„ç†æˆJSONå­—ç¬¦ä¸², åŒ…æ‹¬`"instruction"`, `"schema"`, `"input"`ä¸‰ä¸ªå­—æ®µ |
| output | è¾“å‡º, é‡‡ç”¨å­—å…¸çš„jsonå­—ç¬¦ä¸²çš„æ ¼å¼, keyæ˜¯schema, valueæ˜¯æŠ½å–å‡ºçš„å†…å®¹ |


åœ¨`IEPile`ä¸­, **`instruction`** çš„æ ¼å¼é‡‡çº³äº†ç±»JSONå­—ç¬¦ä¸²çš„ç»“æ„ï¼Œå®è´¨ä¸Šæ˜¯ä¸€ç§å­—å…¸å‹å­—ç¬¦ä¸²ï¼Œå®ƒç”±ä»¥ä¸‹ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†æ„æˆï¼š
(1) **`'instruction'`**: ä»»åŠ¡æè¿°, å®ƒæ¦‚è¿°äº†æŒ‡ä»¤çš„æ‰§è¡Œä»»åŠ¡(`NER`ã€`RE`ã€`EE`ã€`EET`ã€`EEA`ä¹‹ä¸€)ã€‚
(2) **`'schema'`**: å¾…æŠ½å–çš„schema(`å®ä½“ç±»å‹`, `å…³ç³»ç±»å‹`, `äº‹ä»¶ç±»å‹`)åˆ—è¡¨ã€‚
(3) **`'input'`**: å¾…æŠ½å–çš„æ–‡æœ¬ã€‚


ä»¥ä¸‹æ˜¯ä¸€æ¡**æ•°æ®å®ä¾‹**ï¼š

```json
{
  "task": "NER", 
  "source": "MSRA", 
  "instruction": "{\"instruction\": \"ä½ æ˜¯ä¸“é—¨è¿›è¡Œå®ä½“æŠ½å–çš„ä¸“å®¶ã€‚è¯·ä»inputä¸­æŠ½å–å‡ºç¬¦åˆschemaå®šä¹‰çš„å®ä½“ï¼Œä¸å­˜åœ¨çš„å®ä½“ç±»å‹è¿”å›ç©ºåˆ—è¡¨ã€‚è¯·æŒ‰ç…§JSONå­—ç¬¦ä¸²çš„æ ¼å¼å›ç­”ã€‚\", \"schema\": [\"ç»„ç»‡æœºæ„\", \"åœ°ç†ä½ç½®\", \"äººç‰©\"], \"input\": \"å¯¹äºåº·æœ‰ä¸ºã€æ¢å¯è¶…ã€è°­å—£åŒã€ä¸¥å¤è¿™äº›ä»æ—§æ–‡åŒ–è¥å’ä¸­èµ°æ¥çš„å¹´è½»â€œå¸ƒè¡£â€ï¼Œä»–ä»¬èƒŒè´Ÿç€æ²‰é‡çš„å†å²åŒ…è¢±ï¼Œèƒ½å¤ŸæŒ£è„±æ—§ä¼ ç»Ÿçš„æŸç¼šï¼Œä¸ºæ‹¯æ•‘æ°‘æ—çš„å±äº¡è€ŒçŒ®èº«ï¼Œå®åœ¨æ˜¯ä¸­åæ°‘æ—çš„è„Šæ¢ã€‚\"}", 
  "output": "{\"ç»„ç»‡æœºæ„\": [], \"åœ°ç†ä½ç½®\": [\"ä¸­å\"], \"äººç‰©\": [\"åº·æœ‰ä¸º\", \"æ¢å¯è¶…\", \"è°­å—£åŒ\", \"ä¸¥å¤\"]}"
}
```

è¯¥æ•°æ®å®ä¾‹æ‰€å±ä»»åŠ¡æ˜¯ `NER`, æ‰€å±æ•°æ®é›†æ˜¯ `MSRA`, å¾…æŠ½å–çš„schemaåˆ—è¡¨æ˜¯ ["ç»„ç»‡æœºæ„", "åœ°ç†ä½ç½®", "äººç‰©"], å¾…æŠ½å–çš„æ–‡æœ¬æ˜¯"*å¯¹äºåº·æœ‰ä¸ºã€æ¢å¯è¶…ã€è°­å—£åŒã€ä¸¥å¤è¿™äº›ä»æ—§æ–‡åŒ–è¥å’ä¸­èµ°æ¥çš„å¹´è½»â€œå¸ƒè¡£â€ï¼Œä»–ä»¬èƒŒè´Ÿç€æ²‰é‡çš„å†å²åŒ…è¢±ï¼Œèƒ½å¤ŸæŒ£è„±æ—§ä¼ ç»Ÿçš„æŸç¼šï¼Œä¸ºæ‹¯æ•‘æ°‘æ—çš„å±äº¡è€ŒçŒ®èº«ï¼Œå®åœ¨æ˜¯ä¸­åæ°‘æ—çš„è„Šæ¢ã€‚*", è¾“å‡ºæ˜¯ `{"ç»„ç»‡æœºæ„": [], "åœ°ç†ä½ç½®": ["ä¸­å"], "äººç‰©": ["åº·æœ‰ä¸º", "æ¢å¯è¶…", "è°­å—£åŒ", "ä¸¥å¤"]}`

</details>


### 2.2è®­ç»ƒæ•°æ®è½¬æ¢

é¦–å…ˆ, éœ€è¦å°†**æ•°æ®æ ¼å¼åŒ–**ä»¥åŒ…å«`instruction`ã€`output`å­—æ®µã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªè„šæœ¬ [convert_func.py](./ie2instruction/convert_func.py)ï¼Œå®ƒå¯ä»¥å°†æ•°æ®æ‰¹é‡è½¬æ¢æˆæ¨¡å‹å¯ä»¥ç›´æ¥ä½¿ç”¨çš„æ ¼å¼ã€‚

> åœ¨ä½¿ç”¨ [convert_func.py](./ie2instruction/convert_func.py) è„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿å‚è€ƒäº† [data](./data) ç›®å½•ã€‚è¯¥ç›®å½•è¯¦ç»†è¯´æ˜äº†æ¯ç§ä»»åŠ¡æ‰€éœ€çš„æ•°æ®æ ¼å¼è¦æ±‚ã€‚ `sample.json` æè¿°äº†è½¬æ¢å‰æ•°æ®çš„æ ¼å¼ï¼Œ`schema.json` å±•ç¤ºäº† schema çš„ç»„ç»‡ç»“æ„ï¼Œ `train.json` æè¿°äº†è½¬æ¢åçš„æ•°æ®æ ¼å¼ã€‚

> æ­¤å¤–ï¼Œå¯ç›´æ¥ä½¿ç”¨åŒ…å«12ä¸ªä¸»é¢˜ï¼ˆå¦‚äººç‰©ã€äº¤é€šå·¥å…·ã€è‰ºæœ¯ä½œå“ã€è‡ªç„¶ç§‘å­¦ã€äººé€ ç‰©å“ã€å¤©æ–‡å¯¹è±¡ç­‰ï¼‰çš„ä¸­è‹±åŒè¯­ä¿¡æ¯æŠ½å–æ•°æ®é›† [zjunlp/InstructIE](https://huggingface.co/datasets/zjunlp/InstructIE)ã€‚


```bash
python ie2instruction/convert_func.py \
    --src_path data/NER/sample.json \
    --tgt_path data/NER/train.json \
    --schema_path data/NER/schema.json \
    --language zh \
    --task NER \
    --split_num 6 \       
    --random_sort \
    --split train
```

* `language`: æ”¯æŒ`zh`, `en`ä¸¤ç§è¯­è¨€, ä¸åŒè¯­è¨€ä½¿ç”¨çš„æŒ‡ä»¤æ¨¡ç‰ˆä¸åŒã€‚
* `task`: ç›®å‰æ”¯æŒ['`RE`', '`NER`', '`EE`', '`EET`', '`EEA`']äº”ç±»ä»»åŠ¡ã€‚
* `split_num`: å®šä¹‰å•ä¸ªæŒ‡ä»¤ä¸­å¯åŒ…å«çš„æœ€å¤§schemaæ•°ç›®ã€‚é»˜è®¤å€¼ä¸º4ï¼Œè®¾ç½®ä¸º-1åˆ™ä¸è¿›è¡Œåˆ‡åˆ†ã€‚æ¨èçš„ä»»åŠ¡åˆ‡åˆ†æ•°é‡ä¾ä»»åŠ¡è€Œå¼‚ï¼š**NERå»ºè®®ä¸º6ï¼ŒREã€EEã€EETã€EEAå‡æ¨èä¸º4**ã€‚
* `random_sort`: æ˜¯å¦å¯¹æŒ‡ä»¤ä¸­çš„schemaéšæœºæ’åº, é»˜è®¤ä¸ºFalse, å³æŒ‰å­—æ¯é¡ºåºæ’åºã€‚
* `split`: æŒ‡å®šæ•°æ®é›†ç±»å‹ï¼Œå¯é€‰`train`æˆ–`test`ã€‚

è½¬æ¢åçš„è®­ç»ƒæ•°æ®å°†åŒ…å« `task`, `source`, `instruction`, `output` å››ä¸ªå­—æ®µã€‚


### 2.3æµ‹è¯•æ•°æ®è½¬æ¢

åœ¨å‡†å¤‡æµ‹è¯•æ•°æ®è½¬æ¢ä¹‹å‰ï¼Œè¯·è®¿é—® [data](./data) ç›®å½•ä»¥äº†è§£å„ä»»åŠ¡æ‰€éœ€çš„æ•°æ®ç»“æ„ï¼š1ï¼‰è¾“å…¥æ•°æ®æ ¼å¼å‚è§ `sample.json`ï¼›2ï¼‰schemaæ ¼å¼è¯·æŸ¥çœ‹ `schema.json`ï¼›3ï¼‰è½¬æ¢åæ•°æ®æ ¼å¼å¯å‚ç…§ `train.json`ã€‚**ä¸è®­ç»ƒæ•°æ®ä¸åŒ, æµ‹è¯•æ•°æ®çš„è¾“å…¥æ— éœ€åŒ…å«æ ‡æ³¨å­—æ®µï¼ˆ`entity`, `relation`, `event`ï¼‰**ã€‚


```bash
python ie2instruction/convert_func.py \
    --src_path data/NER/sample.json \
    --tgt_path data/NER/test.json \
    --schema_path data/NER/schema.json \
    --language zh \
    --task NER \
    --split_num 6 \
    --split test
```

è®¾ç½® `split` ä¸º **test** æ—¶ï¼Œè¯·æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©é€‚å½“çš„schemaæ•°é‡ï¼š**NERæ¨èä¸º6ï¼Œè€ŒREã€EEã€EETã€EEAæ¨èä¸º4**ã€‚è½¬æ¢åçš„æµ‹è¯•æ•°æ®å°†å«æœ‰`id`, `task`, `source`, `instruction`, `label`äº”ä¸ªå­—æ®µã€‚

`label` å­—æ®µå°†ç”¨äºåç»­è¯„ä¼°ã€‚è‹¥è¾“å…¥æ•°æ®ä¸­ç¼ºå°‘æ ‡æ³¨å­—æ®µï¼ˆ`entity`, `relation`, `event`ï¼‰ï¼Œåˆ™è½¬æ¢åçš„æµ‹è¯•æ•°æ®å°†ä¸åŒ…å«`label`å­—æ®µï¼Œé€‚ç”¨äºé‚£äº›æ— åŸå§‹æ ‡æ³¨æ•°æ®çš„åœºæ™¯ã€‚





## ğŸš´ 3.å‡†å¤‡


### ğŸ› ï¸ 3.1ç¯å¢ƒ
åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ ¹æ®[DeepKE/example/llm/README_CN.md](../README_CN.md/#ç¯å¢ƒä¾èµ–)ä¸­çš„æŒ‡å¯¼åˆ›å»ºäº†é€‚å½“çš„Pythonè™šæ‹Ÿç¯å¢ƒã€‚åˆ›å»ºå¹¶é…ç½®å¥½**è™šæ‹Ÿç¯å¢ƒ**åï¼Œè¯·é€šè¿‡ä»¥ä¸‹å‘½ä»¤æ¿€æ´»åä¸º `deepke-llm` çš„ç¯å¢ƒï¼š

```bash
conda activate deepke-llm
```


```bash
mkdir results
mkdir lora
mkdir data
```

æ•°æ®æ”¾åœ¨ç›®å½• `./data` ä¸­ã€‚


### ğŸ 3.2æ¨¡å‹

ä»¥ä¸‹æ˜¯æœ¬ä»“åº“ä»£ç æ”¯æŒçš„ä¸€äº›åŸºç¡€æ¨¡å‹ï¼š[[llama](https://huggingface.co/meta-llama), [alpaca](https://github.com/tloen/alpaca-lora), [vicuna](https://huggingface.co/lmsys), [zhixi](https://github.com/zjunlp/KnowLM), [falcon](https://huggingface.co/tiiuae), [baichuan](https://huggingface.co/baichuan-inc), [chatglm](https://huggingface.co/THUDM), [qwen](https://huggingface.co/Qwen), [moss](https://huggingface.co/fnlp), [openba](https://huggingface.co/OpenBA)]



## ğŸŒ° 4.LoRAå¾®è°ƒ

ä¸‹é¢æ˜¯ä¸€äº›å·²ç»ç»è¿‡å……åˆ†ä¿¡æ¯æŠ½å–æŒ‡ä»¤æ•°æ®è®­ç»ƒçš„æ¨¡å‹ï¼š

* [zjunlp/llama2-13b-iepile-lora](https://huggingface.co/zjunlp/llama2-13b-iepile-lora/tree/main) ï¼ˆåº•åº§æ¨¡å‹æ˜¯LLaMA2-13B-Chatï¼‰
* [zjunlp/baichuan2-13b-iepile-lora](https://huggingface.co/zjunlp/baichuan2-13b-iepile-lora) ï¼ˆåº•åº§æ¨¡å‹æ˜¯BaiChuan2-13B-Chatï¼‰
* [zjunlp/knowlm-ie-v2](https://huggingface.co/zjunlp/knowlm-ie-v2)


### 4.1åŸºç¡€å‚æ•°

> é‡è¦æç¤ºï¼šä»¥ä¸‹çš„æ‰€æœ‰å‘½ä»¤å‡åº”åœ¨InstrctKGCç›®å½•ä¸‹æ‰§è¡Œã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æƒ³è¿è¡Œå¾®è°ƒè„šæœ¬ï¼Œæ‚¨åº”è¯¥ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤ï¼šbash ft_scripts/fine_llama.bashã€‚è¯·ç¡®ä¿æ‚¨çš„å½“å‰å·¥ä½œç›®å½•æ­£ç¡®ã€‚


```bash
output_dir='lora/llama2-13b-chat-v1'
mkdir -p ${output_dir}
CUDA_VISIBLE_DEVICES="0,1,2,3" torchrun --nproc_per_node=4 --master_port=1287 src/finetune.py \
    --do_train --do_eval \
    --overwrite_output_dir \
    --model_name_or_path 'models/llama2-13b-chat' \
    --stage 'sft' \
    --model_name 'llama' \
    --template 'llama2' \
    --train_file 'data/train.json' \
    --valid_file 'data/dev.json' \
    --output_dir=${output_dir} \
    --per_device_train_batch_size 2 \
    --per_device_eval_batch_size 2 \
    --gradient_accumulation_steps 4 \
    --preprocessing_num_workers 16 \
    --num_train_epochs 10 \
    --learning_rate 5e-5 \
    --max_grad_norm 0.5 \
    --optim "adamw_torch" \
    --max_source_length 400 \
    --cutoff_len 700 \
    --max_target_length 300 \
    --evaluation_strategy "epoch" \
    --save_strategy "epoch" \
    --save_total_limit 10 \
    --lora_r 16 \
    --lora_alpha 32 \
    --lora_dropout 0.05 \
    --bf16 \
    --deepspeed configs/ds_config_bf16.json
```

* `model_name`: æŒ‡å®šæ‰€éœ€çš„**æ¨¡å‹æ¶æ„åç§°**(7Bã€13Bã€Baseã€Chatå±äºåŒä¸€æ¨¡å‹æ¶æ„)ã€‚å½“å‰æ”¯æŒçš„æ¨¡å‹åŒ…æ‹¬ï¼š["`llama`", "`alpaca`", "`vicuna`", "`zhixi`", "`falcon`", "`baichuan`", "`chatglm`", "`qwen`", "`moss`", "`openba`"]ã€‚**è¯·æ³¨æ„**ï¼Œæ­¤å‚æ•°åº”ä¸ `--model_name_or_path` åŒºåˆ†ã€‚
* `model_name_or_path`: æ¨¡å‹è·¯å¾„, è¯·åˆ° [HuggingFace](https://huggingface.co/models) ä¸‹è½½ç›¸åº”æ¨¡å‹ã€‚
* `template`: ä½¿ç”¨çš„**æ¨¡æ¿åç§°**ï¼ŒåŒ…æ‹¬ï¼š`alpaca`, `baichuan`, `baichuan2`, `chatglm3`ç­‰, è¯·å‚è€ƒ [src/datamodule/template.py](./src/datamodule/template.py) æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„æ¨¡ç‰ˆåç§°, é»˜è®¤ä½¿ç”¨çš„æ˜¯`alpaca`æ¨¡æ¿, **`Chat`ç‰ˆæœ¬çš„æ¨¡å‹å»ºè®®ä½¿ç”¨é…å¥—çš„æ¨¡ç‰ˆ, Baseç‰ˆæœ¬æ¨¡å‹å¯é»˜è®¤ä½¿ç”¨`alpaca`**ã€‚
* `train_file`, `valid_fileï¼ˆå¯é€‰ï¼‰`: è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„**æ–‡ä»¶è·¯å¾„**ã€‚æ³¨æ„ï¼šç›®å‰ä»…æ”¯æŒjsonæ ¼å¼çš„æ–‡ä»¶ã€‚
* `output_dir`: LoRAå¾®è°ƒåçš„**æƒé‡å‚æ•°ä¿å­˜è·¯å¾„**ã€‚
* `val_set_size`: **éªŒè¯é›†çš„æ ·æœ¬æ•°é‡**, é»˜è®¤ä¸º1000ã€‚
* `per_device_train_batch_size`, `per_device_eval_batch_size`: æ¯å°GPUè®¾å¤‡ä¸Šçš„`batch_size`, æ ¹æ®æ˜¾å­˜å¤§å°è°ƒæ•´, RTX3090å»ºè®®è®¾ç½®2~4ã€‚
* `max_source_length`, `max_target_length`, `cutoff_len`: æœ€å¤§è¾“å…¥ã€è¾“å‡ºé•¿åº¦ã€æˆªæ–­é•¿åº¦, æˆªæ–­é•¿åº¦å¯ä»¥ç®€å•åœ°è§†ä½œæœ€å¤§è¾“å…¥é•¿åº¦ + æœ€å¤§è¾“å‡ºé•¿åº¦, éœ€æ ¹æ®å…·ä½“éœ€æ±‚å’Œæ˜¾å­˜å¤§å°è®¾ç½®åˆé€‚å€¼ã€‚
* `deepspeed`: è®¾å¤‡èµ„æºä¸å¤Ÿå¯å»æ‰ã€‚

> å¯é€šè¿‡è®¾ç½® `bits` = 4 è¿›è¡Œé‡åŒ–, RTX3090å»ºè®®é‡åŒ–ã€‚

* è¦äº†è§£æ›´å¤šå…³äº**å‚æ•°é…ç½®**çš„ä¿¡æ¯ï¼Œè¯·å‚è€ƒ [src/utils/args](./src/args) ç›®å½•ã€‚


### 4.2LoRAå¾®è°ƒLLaMA

å¾®è°ƒLLaMAæ¨¡å‹çš„å…·ä½“è„šæœ¬å¯ä»¥åœ¨ [ft_scripts/fine_llama.bash](./ft_scripts/fine_llama.bash) ä¸­æ‰¾åˆ°ã€‚


### 4.3LoRAå¾®è°ƒAlpaca

å¾®è°ƒAlpacaæ¨¡å‹æ—¶ï¼Œæ‚¨å¯éµå¾ªä¸[å¾®è°ƒLLaMAæ¨¡å‹](./README_CN.md/#42loraå¾®è°ƒllama)ç±»ä¼¼çš„æ­¥éª¤ã€‚è¦è¿›è¡Œå¾®è°ƒï¼Œè¯·å¯¹[ft_scripts/fine_llama.bash](./ft_scripts/fine_llama.bash)æ–‡ä»¶åšå‡ºä»¥ä¸‹**ä¿®æ”¹**ï¼š

```bash
output_dir='path to save Alpaca Lora'
--model_name_or_path 'path or name to Alpaca' \
--template 'alpaca' \
--model_name 'alpaca' \
```

1. å¯¹äºtemplateï¼Œæˆ‘ä»¬**é»˜è®¤ä½¿ç”¨alpacaæ¨¡æ¿**ã€‚
2. `model_name = alpaca`


### 4.4LoRAå¾®è°ƒæ™ºæ

```bash
output_dir='path to save Zhixi Lora'
--model_name_or_path 'path or name to Zhixi' \
--model_name 'zhixi' \
--template 'alpaca' \
```

1. ç”±äºZhixiç›®å‰åªæœ‰13bçš„æ¨¡å‹, å»ºè®®ç›¸åº”åœ°å‡å°æ‰¹å¤„ç†å¤§å°batch size
2. å¯¹äºtemplateï¼Œæˆ‘ä»¬**é»˜è®¤ä½¿ç”¨alpacaæ¨¡æ¿**ã€‚
3. `model_name = zhixi`




### 4.5LoRAå¾®è°ƒVicuna

ç›¸åº”çš„è„šæœ¬åœ¨ [ft_scripts/fine_vicuna.bash](./ft_scripts//fine_vicuna.bash)

1. ç”±äºVicuna-7b-delta-v1.1æ‰€ä½¿ç”¨çš„templateä¸`alpaca`**æ¨¡ç‰ˆä¸åŒ**, å› æ­¤éœ€è¦è®¾ç½® `template vicuna`ã€‚
2. `model_name = vicuna`



### 4.6LoRAå¾®è°ƒChatGLM

ç›¸åº”çš„è„šæœ¬åœ¨ [ft_scripts/fine_chatglm.bash](./ft_scripts//fine_chatglm.bash)

1. ChatGLMæ¨¡å‹æˆ‘ä»¬é‡‡ç”¨[THUDM/chatglm3-6b](https://huggingface.co/THUDM/chatglm3-6b)
2. `model_name = chatglm`
3. `template chatglm3`



### 4.7LoRAå¾®è°ƒMoss

ç›¸åº”çš„è„šæœ¬åœ¨ [ft_scripts/fine_moss.bash](./ft_scripts/fine_moss.bash)

1. Mossæ¨¡å‹æˆ‘ä»¬é‡‡ç”¨[moss-moon-003-sft](https://huggingface.co/fnlp/moss-moon-003-sft)
2. `model_name = moss`
  

### 4.8LoRAå¾®è°ƒBaichuan

ç›¸åº”çš„è„šæœ¬åœ¨ [ft_scripts/fine_baichuan.bash](./ft_scripts/fine_baichuan.bash)

1. Baichuanæ¨¡å‹æˆ‘ä»¬é‡‡ç”¨[baichuan-inc/Baichuan2-7B-Base](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base)
2. **è¯·ç¡®ä¿torchç‰ˆæœ¬ä¿æŒåœ¨2.0.0, å¦åˆ™å¯èƒ½å‡ºç°é—®é¢˜**
3. `model_name = baichuan`
4. `template baichuan2`
5. æˆ‘ä»¬å»ºè®®ä½¿ç”¨ `--bf16`
6. å¦‚æœå‡ºç°åœ¨evalåä¿å­˜æ—¶çˆ†æ˜¾å­˜è¯·è®¾ç½® `evaluation_strategy no`


### 4.9é¢†åŸŸå†…æ•°æ®ç»§ç»­è®­ç»ƒ

å°½ç®¡ `llama2-13b-iepile-lora`ã€`baichuan2-13b-iepile-lora` ç­‰æ¨¡å‹å·²åœ¨å¤šä¸ªé€šç”¨æ•°æ®é›†ä¸Šæ¥å—äº†å¹¿æ³›çš„æŒ‡ä»¤å¾®è°ƒï¼Œå¹¶å› æ­¤è·å¾—äº†ä¸€å®šçš„**é€šç”¨ä¿¡æ¯æŠ½å–èƒ½åŠ›**ï¼Œä½†å®ƒä»¬åœ¨**ç‰¹å®šé¢†åŸŸ**ï¼ˆå¦‚`æ³•å¾‹`ã€`æ•™è‚²`ã€`ç§‘å­¦`ã€`ç”µä¿¡`ï¼‰çš„æ•°æ®å¤„ç†ä¸Šå¯èƒ½ä»æ˜¾ç¤ºå‡ºä¸€å®šçš„å±€é™æ€§ã€‚é’ˆå¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œå»ºè®®å¯¹è¿™äº›æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸçš„æ•°æ®é›†ä¸Šè¿›è¡Œ**äºŒæ¬¡è®­ç»ƒ**ã€‚è¿™å°†æœ‰åŠ©äºæ¨¡å‹æ›´å¥½åœ°é€‚åº”ç‰¹å®šé¢†åŸŸçš„è¯­ä¹‰å’Œç»“æ„ç‰¹å¾ï¼Œä»è€Œå¢å¼ºå…¶åœ¨**è¯¥é¢†åŸŸå†…çš„ä¿¡æ¯æŠ½å–èƒ½åŠ›**ã€‚


```bash
output_dir='lora/llama2-13b-chat-v1-continue'
mkdir -p ${output_dir}
CUDA_VISIBLE_DEVICES="0,1,2,3" torchrun --nproc_per_node=4 --master_port=1287 src/finetune.py \
    --do_train --do_eval \
    --overwrite_output_dir \
    --model_name_or_path 'models/llama2-13B-Chat' \
    --checkpoint_dir 'lora/llama2-13b-iepile-lora' \
    --stage 'sft' \
    --model_name 'llama' \
    --template 'llama2' \
    --train_file 'data/train.json' \
    --valid_file 'data/dev.json' \
    --output_dir=${output_dir} \
    --per_device_train_batch_size 2 \
    --per_device_eval_batch_size 2 \
    --gradient_accumulation_steps 4 \
    --preprocessing_num_workers 16 \
    --num_train_epochs 10 \
    --learning_rate 5e-5 \
    --max_grad_norm 0.5 \
    --optim "adamw_torch" \
    --max_source_length 400 \
    --cutoff_len 700 \
    --max_target_length 300 \
    --evaluation_strategy "epoch" \
    --save_strategy "epoch" \
    --save_total_limit 10 \
    --lora_r 64 \
    --lora_alpha 64 \
    --lora_dropout 0.05 \
    --bf16 
```

* è‹¥è¦åŸºäºå¾®è°ƒåçš„LoRAæƒé‡ç»§ç»­è®­ç»ƒï¼Œä»…éœ€å°† `checkpoint_dir` å‚æ•°æŒ‡å‘LoRAæƒé‡è·¯å¾„ï¼Œä¾‹å¦‚è®¾ç½®ä¸º`'zjunlp/llama2-13b-iepile-lora'`ã€‚

> å¯é€šè¿‡è®¾ç½® `bits` = 4 è¿›è¡Œé‡åŒ–, RTX3090å»ºè®®é‡åŒ–ã€‚

> è¯·æ³¨æ„ï¼Œåœ¨ä½¿ç”¨ `llama2-13b-iepile-lora`ã€`baichuan2-13b-iepile-lora` æ—¶ï¼Œä¿æŒlora_rå’Œlora_alphaå‡ä¸º64ï¼Œå¯¹äºè¿™äº›å‚æ•°ï¼Œæˆ‘ä»¬ä¸æä¾›æ¨èè®¾ç½®ã€‚

* è‹¥è¦åŸºäºå¾®è°ƒåçš„æ¨¡å‹æƒé‡ç»§ç»­è®­ç»ƒï¼Œåªéœ€è®¾å®š `model_name_or_path` å‚æ•°ä¸ºæƒé‡è·¯å¾„ï¼Œå¦‚`'zjunlp/KnowLM-IE-v2'`ï¼Œæ— éœ€è®¾ç½®`checkpoint_dir`ã€‚


è„šæœ¬å¯ä»¥åœ¨ [ft_scripts/fine_continue.bash](./ft_scripts/fine_continue.bash) ä¸­æ‰¾åˆ°ã€‚



## ğŸ¥Š 5.P-Tuningå¾®è°ƒ

### 5.1P-Tuningå¾®è°ƒChatGLM

ä½ å¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤ä½¿ç”¨P-Tuningæ–¹æ³•æ¥finetuneæ¨¡å‹:

```bash
deepspeed --include localhost:0 src/finetuning_pt.py \
  --train_path data/train.json \
  --model_dir /model \
  --num_train_epochs 20 \
  --train_batch_size 2 \
  --gradient_accumulation_steps 1 \
  --output_dir output_dir_pt \
  --log_steps 10 \
  --max_len 768 \
  --max_src_len 450 \
  --pre_seq_len 16 \
  --prefix_projection true
```


## ğŸ”´ 6.é¢„æµ‹

### 6.1LoRAé¢„æµ‹

#### 6.1.1åŸºç¡€æ¨¡å‹+Lora

ä»¥ä¸‹æ˜¯ä¸€äº›ç»è¿‡LoRAæŠ€æœ¯è®­ç»ƒä¼˜åŒ–çš„æ¨¡å‹(**Loraæƒé‡**)ï¼š

<details>
  <summary><b>V1ç‰ˆæœ¬</b></summary>

* [alpaca-7b-lora-ie](https://huggingface.co/zjunlp/alpaca-7b-lora-ie)
* [llama-7b-lora-ie](https://huggingface.co/zjunlp/llama-7b-lora-ie)
* [alpaca-13b-lora-ie](https://huggingface.co/zjunlp/alpaca-13b-lora-ie)
* [knowlm-13b-ie-lora](https://huggingface.co/zjunlp/knowlm-13b-ie-lora)


| checkpoint_dir | model_name_or_path | moadel_name | fp16/bf16 | template | 
| --- | --- | --- | --- | --- |
| llama-7b-lora-ie | llama-7b | llama | fp16 | alpaca |
| alpaca-7b-lora-ie | alpaca-7b | alpaca | fp16 | alpaca |
| knowlm-13b-ie-lora | zhixi | fp16 | alpaca |

</details>

<details>
  <summary><b>V2ç‰ˆæœ¬(æ¨è)</b></summary>

* [zjunlp/llama2-13b-iepile-lora](https://huggingface.co/zjunlp/llama2-13b-iepile-lora/tree/main) 
* [zjunlp/baichuan2-13b-iepile-lora](https://huggingface.co/zjunlp/baichuan2-13b-iepile-lora) 
* [zjunlp/knowlm-ie-v2](https://huggingface.co/zjunlp/knowlm-ie-v2)


| checkpoint_dir | model_name_or_path | moadel_name | fp16/bf16 | template | 
| --- | --- | --- | --- | --- |
| llama2-13b-iepile-lora | LLaMA2-13B-Chat | llama | bf16 | llama2 |
| baichuan2-13b-iepile-lora | BaiChuan2-13B-Chat | baichuan | bf16 | baichuan2 |

</details>


è¦ä½¿ç”¨è¿™äº›**è®­ç»ƒå¥½çš„**LoRAæ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œå¯ä»¥æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
CUDA_VISIBLE_DEVICES=0 python src/inference.py \
    --stage sft \
    --model_name_or_path 'models/llama2-13B-Chat' \
    --checkpoint_dir 'lora/llama2-13b-IEPile-lora' \
    --model_name 'llama' \
    --template 'llama2' \
    --do_predict \
    --input_file 'data/input.json' \
    --output_file 'results/llama2-13b-IEPile-lora_output.json' \
    --finetuning_type lora \
    --output_dir 'lora/test' \
    --predict_with_generate \
    --cutoff_len 512 \
    --bf16 \
    --max_new_tokens 300
```

* åœ¨è¿›è¡Œæ¨ç†æ—¶ï¼Œ`model_name`, `template`, å’Œ `bf16` å¿…é¡»ä¸è®­ç»ƒæ—¶çš„è®¾ç½®ç›¸åŒã€‚
* `model_name_or_path`: æŒ‡å®šæ‰€ä½¿ç”¨çš„åŸºç¡€æ¨¡å‹è·¯å¾„ï¼Œå¿…é¡»ä¸ç›¸åº”çš„LoRAæ¨¡å‹åŒ¹é…ã€‚
* `checkpoint_dir`: LoRAçš„æƒé‡æ–‡ä»¶è·¯å¾„ã€‚
* `output_dir`: æ­¤å‚æ•°åœ¨æ¨ç†æ—¶ä¸èµ·ä½œç”¨ï¼Œå¯ä»¥éšæ„æŒ‡å®šä¸€ä¸ªè·¯å¾„ã€‚
* `input_file`, `output_file`: åˆ†åˆ«æŒ‡å®šè¾“å…¥çš„æµ‹è¯•æ–‡ä»¶è·¯å¾„å’Œé¢„æµ‹ç»“æœçš„è¾“å‡ºæ–‡ä»¶è·¯å¾„ã€‚
* `cutoff_len`, `max_new_tokens`: è®¾ç½®æœ€å¤§çš„è¾“å…¥é•¿åº¦å’Œç”Ÿæˆçš„æ–°tokenæ•°é‡ï¼Œæ ¹æ®æ˜¾å­˜å¤§å°è¿›è¡Œè°ƒæ•´ã€‚

> å¯é€šè¿‡è®¾ç½® `bits` = 4 è¿›è¡Œé‡åŒ–, RTX3090å»ºè®®é‡åŒ–ã€‚


#### 6.1.2IEä¸“ç”¨æ¨¡å‹
è‹¥è¦ä½¿ç”¨**å·²è®­ç»ƒçš„æ¨¡å‹**ï¼ˆæ— LoRAæˆ–LoRAå·²é›†æˆåˆ°æ¨¡å‹å‚æ•°ä¸­ï¼‰ï¼Œå¯ä»¥æ‰§è¡Œä»¥ä¸‹å‘½ä»¤è¿›è¡Œé¢„æµ‹ï¼š

```bash
CUDA_VISIBLE_DEVICES=0 python src/inference.py \
    --stage sft \
    --model_name_or_path 'models/KnowLM-IE-v2' \
    --model_name 'baichuan' \
    --template 'baichuan2' \
    --do_predict \
    --input_file 'data/input.json' \
    --output_file 'results/KnowLM-IE-v2_output.json' \
    --output_dir 'lora/test' \
    --predict_with_generate \
    --cutoff_len 512 \
    --bf16 \
    --max_new_tokens 300 
```

`model_name_or_path`: IEä¸“ç”¨æ¨¡å‹æƒé‡è·¯å¾„



### 6.2P-Tuningé¢„æµ‹

ä½ å¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤ä½¿ç”¨è®­ç»ƒå¥½çš„P-Tuningæ¨¡å‹åœ¨æ¯”èµ›æµ‹è¯•é›†ä¸Šé¢„æµ‹è¾“å‡º:
```bash
CUDA_VISIBLE_DEVICES=0 python src/inference_pt.py \
  --test_path data/valid.json \
  --device 0 \
  --ori_model_dir /model \
  --model_dir /output_dir_lora/global_step- \
  --max_len 768 \
  --max_src_len 450
```


## ğŸ§¾ 7.è¯„ä¼°

æˆ‘ä»¬æä¾›äº†è¯„ä¼°å„ä¸ªä»»åŠ¡F1åˆ†æ•°çš„è„šæœ¬ã€‚

```bash
python ie2instruction/eval_func.py \
  --path1 data/NER/processed.json \
  --task NER 
```

* `task`: ç›®å‰æ”¯æŒ['RE', 'NER', 'EE', 'EET', 'EEA']äº”ç±»ä»»åŠ¡ã€‚
* å¯ä»¥è®¾ç½® `sort_by` ä¸º `source`, åˆ†åˆ«è®¡ç®—æ¯ä¸ªæ•°æ®é›†ä¸Šçš„F1åˆ†æ•°ã€‚




## ğŸ‘‹ 8.Acknowledgment

Part of the code is derived from [Alpaca-LoRA](https://github.com/tloen/alpaca-lora) and [hiyouga/LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory). We extend our gratitude for their contributions!


## 9.å¼•ç”¨
å¦‚æœæ‚¨ä½¿ç”¨IEPileæˆ–ä»£ç ï¼Œè¯·å¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š

```bibtex
@article{DBLP:journals/corr/abs-2305-11527,
  author       = {Honghao Gui and Shuofei Qiao and Jintian Zhang and Hongbin Ye and Mengshu Sun and Lei Liang and Huajun Chen and Ningyu Zhang},
  title        = {InstructIE: A Bilingual Instruction-based Information Extraction Dataset},
  journal      = {CoRR},
  volume       = {abs/2305.11527},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.11527},
  doi          = {10.48550/arXiv.2305.11527},
  eprinttype    = {arXiv},
  eprint       = {2305.11527},
  timestamp    = {Thu, 25 May 2023 15:41:47 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2305-11527.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2402-14710,
  author       = {Honghao Gui and
                  Hongbin Ye and
                  Lin Yuan and
                  Ningyu Zhang and
                  Mengshu Sun and
                  Lei Liang and
                  Huajun Chen},
  title        = {IEPile: Unearthing Large-Scale Schema-Based Information Extraction Corpus},
  journal      = {CoRR},
  volume       = {abs/2402.14710},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2402.14710},
  doi          = {10.48550/ARXIV.2402.14710},
  eprinttype   = {arXiv},
  eprint       = {2402.14710},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2402-14710.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
```